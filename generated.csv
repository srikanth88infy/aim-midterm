user_input,reference_contexts,reference,synthesizer_name
Wht is the role of kubernetes in deploying applications?,"['How to resolve the error no module named pandas when one node (in Airflow\'s DAG) is successful in using it(pandas) and the other is not?</p>\\n\\n<p>I am unable to deduce as to why I am getting an error no module named pandas.</p>\\n\\n<p>I have checked via <code>pip3 freeze</code> and yes, the desired pandas version does show up.</p>\\n\\n<p>I have deployed this using docker on a kubernetes cluster.</p>\\n aviral sanjay <p><a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer"">Pandas is generally required</a>, and sometimes used in some hooks to return dataframes. Well, it\'s possible that Airflow was installed with <code>pip</code> and not <code>pip3</code> possibly being added as a Python 2 module and not a Python 3 module (though, using <code>pip</code> should have installed Pandas when one looks at the <a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer""><code>setup.py</code></a>).</p>\\n\\n<p>Which Operator in your DAG is giving this error?\\nDo you have any PythonVirtualEnvironmentOperators or BashOperators running <code>python</code> from the command line (and thus possibly not sharing the same environment that you\'re checking has <code>pandas</code>)?</p>\\n dlamblin <p>I tried to install ibm-eventstreams-dev v 0.1.2 into my Mac. </p>\\n\\n<p>After I installed eventstreams into my Mac, there\'s always several pods that can\'t run. It includes three kafka pods: es-ibm-es-kafka-sts-0/1/2, es-ibm-es-ui-deploy-69758d9dfd-kc2zx, es-ibm-es-ui-oauth2-client-reg-pgvq6 and there also have a failed job named es-ibm-es-ui-oauth2-client-reg. </p>\\n\\n<p>You can see the details in the follow images:\\n<a href=""https://i.stack.imgur.com/Qg3MB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qg3MB.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/n3YpQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n3YpQ.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/h4ZBu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/h4ZBu.png"" alt=""enter image description here""></a></p>\\n\\n<p>So I have two questions about the ibm-event-stream:</p>\\n\\n<ul>\\n<li><p>Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p></li>\\n<li><p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p></li>\\n<li><p>what\'s wrong with the kafka pods? what\'s the status message ""CrashLoopBackOff"" means?</p></li>\\n</ul>\\n\\n<p>My environment details:</p>\\n\\n<ul>\\n<li>kubernetes 1.11.1</li>\\n<li>helm : stable 2.10.0</li>\\n<li>a cluster have three nodes, each nodes is a virtual macine.</li>\\n</ul>\\n\\n<p>Please help me, Thanks a lot!</p>\\n DoubleQueens <blockquote>\\n <p>So I have two questions about the ibm-event-stream:<br>\\n Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p>\\n</blockquote>\\n\\n<p>Event Streams will only run on IBM Cloud Private (ICP). That\'s because ICP provides more than just a Kubernetes environment. For example, authentication and user management for Event Streams is provided by the ICP platform. </p>\\n\\n<p>That\'s what the es-ibm-es-ui-oauth2-client-reg job that is failing for you is trying to do - set up the OAuth integration with ICP. And that\'ll be why it failed for you in Kubernetes on your Mac - because some of the dependencies that Event Streams has will be missing. </p>\\n\\n<blockquote>\\n <p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p>\\n</blockquote>\\n\\n<p>I\'m afraid you won\'t be able to fix this in just K8S on your Mac - all of the problems that you describe are a result of bits of ICP that Event Streams depends on being missing.</p>\\n\\n<p>You can get a Community Edition of ICP (at no charge) from <a href=""https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295"" rel=""nofollow noreferrer"">https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295</a> - which would let you give it a try. </p>\\n dalelane <p>I hope it\'s ok to ask for your advice.</p>\\n<p>The problem in a nutshell: my pipeline cannot pull private images from GHCR.IO into Okteto Kubernetes, but public images from the same private repo work.</p>\\n<p>I\'m on Windows 10 and use WSL2-Ubuntu 20.04 LTS with kinD for development and tried minikube too.</p>\\n<p>I get an error in Okteto which says that the image pull is “unauthorized” -> “imagePullBackOff”.</p>\\n<p>Things I did:browsed Stack Overflow, RTFM, Okteto FAQ, download the Okteto kubeconfig, pulled my hair out and spent more hours than I would like to admit – still no success yet.</p>\\n<p>For whatever reason I cannot create a “kubectl secret” that works. When logged-in to ghcr.io via “docker login --username” I can pull private images locally.</p>\\n<p>No matter what I’ve tried I still get the error “unauthorized” when trying to pull a private image in Okteto.</p>\\n<p>My Setup with latest updates:</p>\\n<ul>\\n<li>Windows 10 Pro</li>\\n<li>JetBrains Rider IDE</li>\\n<li>WSL2-Ubuntu 20.04 LTS</li>\\n<li>ASP.NET Core MVC app</li>\\n<li>.NET 6 SDK</li>\\n<li>Docker</li>\\n<li>kinD</li>\\n<li>minikube</li>\\n<li>Chocolatey</li>\\n<li>Homebrew</li>\\n</ul>\\n<p>Setup kinD</p>\\n<pre><code>kind create cluster --name my-name\\n\\nkubectl create my-namespace\\n\\n// create a secret to pull images from ghcr.io \\nkubectl create secret docker-registry my-secret -n my-namespace --docker-username=""my-username"" --docker-password=""my-password"" --docker-email=""my-email"" --docker-server=""https://ghcr.io""\\n\\n// patch local service account\\nkubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""my-secret""}]}\'\\n</code></pre>\\n<p>kubernetes.yaml</p>\\n<pre><code>apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: okteto-repo\\n namespace: my-namespace\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: okteto-repo\\n template:\\n metadata:\\n labels:\\n app: okteto-repo\\n spec:\\n containers:\\n - name: okteto-repo\\n image: ghcr.io/user/okteto-repo:latest\\n ports:\\n - containerPort: 80\\n imagePullSecrets:\\n - name: my-secret\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: okteto-repo\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP\\n selector:\\n app: okteto-repo\\n ports:\\n - protocol: TCP\\n port: 8080\\n targetPort: 80\\n</code></pre>\\n<p>Do you have an idea why it doesn\'t work and what I could do?</p>\\n<p>Thanks a lot my dear friends, every input is highly appreciated!</p>\\n<p>Hope you guys have great holidays.</p>\\n<p>Cheers,\\nMichael</p>\\n Michael <p>I was able to pull a private image by doing the following:</p>\\n<ol>\\n<li>Create a personal token in GitHub with <code>repo</code> access.</li>\\n<li>Build and push the image to GitHub\'s Container registry (I used <code>okteto build -t ghcr.io/rberrelleza/go-getting-started:0.0.1</code>)</li>\\n<li>Download my <a href=""https://okteto.com/docs/reference/cli/#update-kubeconfig"" rel=""noreferrer"">kubeconfig credentials</a> from Okteto Cloud by running <code>okteto context update-kubeconfig</code>.</li>\\n<li>Create a secret with my credentials: <code>kubectl create secret docker-registry gh-regcred --docker-server=ghcr.io --docker-username=rberrelleza --docker-password=ghp_XXXXXX</code></li>\\n<li>Patched the default account to include the secret as an image pull secret: <code>kubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""gh-regcred""}]}\'</code></li>\\n<li>Updated the image name in the kubernetes manifest</li>\\n<li>Created the deployment (<code>kubectl apply -f k8s.yaml</code>)</li>\\n</ol>\\n<p>These is what my kubernetes resources looks like, in case it helps:</p>\\n<pre><code># k8s.yaml\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: hello-world\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: hello-world\\n template:\\n metadata:\\n labels:\\n app: hello-world\\n spec:\\n containers:\\n - image: ghcr.io/rberrelleza/go-getting-started:0.0.1\\n name: hello-world\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: hello-world\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP \\n ports:\\n - name: ""hello-world""\\n port: 8080\\n selector:\\n app: hello-world\\n</code></pre>\\n<pre><code># default SA\\napiVersion: v1\\nimagePullSecrets:\\n- name: gh-regcred\\n- name: okteto-regcred\\nkind: ServiceAccount\\nmetadata:\\n creationTimestamp: ""2021-05-21T22:26:38Z""\\n name: default\\n namespace: rberrelleza\\n resourceVersion: ""405042662""\\n uid: 2b6a6eef-2ce7-40d3-841a-c0a5497279f7\\nsecrets:\\n- name: default-token-7tm42\\n</code></pre>\\n Ramiro Berrelleza <p>I\'ve been using the kubectl to upload Airflow workflows to the kubernetes (/usr/local/airflow/dags) manually. It is possible to do this without using the kubectl? by using a python script? or something else? If it\'s possible would you be able to share your source? or your python script? Thanks, Appreciate</p>\\n Mihail <p>This totally depends on your setup. E.G. We use AWS and so we have the DAGs syncing from an S3 bucket path every 5 minutes. We just put dags into']","Kubernetes is used to deploy applications by managing containerized applications across a cluster of machines, ensuring that the desired state of the application is maintained.",single_hop_specifc_query_synthesizer
How can I deploy an Okteto environment on Visual Studio Code for Kubernetes development?,"['S3. I see that some Kubernetes setups use a kind of shared volume defined by a git repository, that might also work. Airflow itself (the webserver(s), worker(s), nor scheduler) does not offer any hook to upload into the DAG directory.</p>\\n dlamblin <p>I\'m trying to deploy okteto environment on Visual Studio Code to use Remote Development on Kubernetes.</p>\\n<p>Following the official steps (<a href=""https://okteto.com/blog/remote-kubernetes-development/"" rel=""nofollow noreferrer"">https://okteto.com/blog/remote-kubernetes-development/</a>), I executed ""Okteto: up"" and selected manifest(vscode-remote-go/okteto.yml), but got this error:</p>\\n<pre><code>Installing dependencies... \\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>By changing the log level, I also got these logs:</p>\\n<pre><code>C:\\Users\\user\\AppData\\Local\\Programs\\okteto.exe up -f \'c:\\Workspace\\...my_project...\\vscode-remote-go\\okteto.yml\' --remote \'22100\' --loglevel=debug\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""starting up command""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to get latest version from github: fail to get releases from github: Get \\""https://api.github.com/repos/okteto/okteto/releases?per_page=5\\"": dial tcp: lookup api.github.com: no such host""\\nInstalling dependencies...\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""failed to upgrade syncthing: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""couldn\'t download syncthing, please try again""\\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>This environment is behind my corporate proxy, and okteto.exe may not use Windows proxy setting. When I directly enter the URL (<a href=""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip"" rel=""nofollow noreferrer"">https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip</a>) it can be downloaded using proxy.</p>\\n<p>Is it possible to use okteto behind proxy?</p>\\n Daigo <p>Using a proxy is not currently supported in the Okteto. We\'re looking into it though.</p>\\n<p>For now, a workaround is to manually download the syncthing binary and save it as<code>%HOME%\\.okteto\\syncthing.exe</code></p>\\n Ramiro Berrelleza <p>Is there currently a way to serve websockets from an application deployed on Okteto cloud given the okteto-specific limitations around <code>Ingress</code>es and <code>Service</code>s ?</p>\\n\\n<hr>\\n\\n<p>I\'ve read that this would only be possible using a <code>Service</code> or <code>Ingress</code> of type <code>LoadBalancer</code>, so that is what I\'ve tried.</p>\\n\\n<p>But, according to the <a href=""https://okteto.com/docs/cloud/build"" rel=""nofollow noreferrer"">Okteto docs</a>, <code>Service</code>s of type <code>LoadBalancer</code> (or <code>NodePort</code>) are managed. In practice they seem to get transformed automatically into a <code>ClusterIP Service</code>, + exposed to the internet on an automatic URL.</p>\\n\\n<p>Do these handle only <code>HTTP</code> requests ? Or is there a way to make them handle other kinds of connections based on TCP or UDP (like websockets) ?</p>\\n Nicolas Marshall <p>You don\'t need a LoadBalancer to use WebSockets, they can be served from an Ingress with a ClusterIP as well (this is what Okteto Cloud uses for our endpoints). This setup supports HTTPS, WebSockets and even GRPC-based endpoints.</p>\\n\\n<p><a href=""https://github.com/okteto/node-websocket"" rel=""nofollow noreferrer"">This sample</a> shows you how to use WebSockets on a Node app deployed in Okteto Cloud, hope it helps! (it uses okteto-generated Kubernetes manifests, but you can also bring your own).</p>\\n Ramiro Berrelleza <p>I was working on Jenkins for many days and deploy my services to Kubernetes.</p>\\n\\n<p>I recently came across Jenkins X, I also found a Helm chart for Jenkins through which I can host Jenkins in Kubernetes. Now I\'m confused if they both are same?</p>\\n RohithVallabhaneni <p>No they are different. I assume the helm chart you found installs and configure Jenkins on Kubernetes - perhaps configured with some agents to run builds. </p>\\n\\n<p>Jenkins X is a kubernetes native implementation of CI/CD, it uses some components of Jenkins, but has a lot more to it (for example, applications, environments, review apps, deployments and so on) for running apps ON kubernetes in a CI/CD fashion. The Jenkins helm chart likely sets up a single server. </p>\\n\\n<p>edit: in the time since, Jenkins X has evolved a lot. It is now build using he Tekton engine for pipeline by default, and has many moving parts, so is quite different from running a more classic like Jenkins master/agent setup in a Kubernetes cluster. </p>\\n Michael Neale <p>Recently, I tried to setup Jenkins X on a kubernetes cluster. However there exists some problem during installation. </p>\\n\\n<p>There are several options in <code>jx create cluster</code> such as aks(create with AKS), aws(create with AWS), minikube(create with Minikube) and etc.</p>\\n\\n<p>However there is no option which create a cluster with local kubernetes cluster. I want to setup Jenkins X with my own cluster. </p>\\n\\n<p>Can I get some advice?</p>\\n\\n<p>Thanks.</p>\\n jwl1993 <p>when you have your cluster setup such that you can run <code>kubectl</code> commands against it, you can run <code>jx boot</code> to setup your jx installation. You don\'t need to use <code>jx create cluster</code> as your cluster already exists. </p>\\n Michael Neale <p>I\'m creating a custom resource definition (CRD) with an associated controller using <a href=""https://github.com/kubernetes-sigs/kubebuilder"" rel=""nofollow noreferrer"">kubebuilder</a>. My controller reconcile loop creates a deployment sub-resource and parents it to the custom resource using <code> controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code>. I\'ve also configured my reconciler so ""own"" the sub-resource, as follows:</p>\\n<pre class=""lang-golang prettyprint-override""><code>// SetupWithManager sets up the controller with the Manager.\\nfunc (r *MyResourceReconciler) SetupWithManager(mgr ctrl.Manager) error {\\n return ctrl.NewControllerManagedBy(mgr).\\n For(&mygroupv1alpha1.MyResource{}).\\n Owns(&appsv1.Deployment{}).\\n Complete(r)\\n}\\n</code></pre>\\n<p>However, when I run my controller locally using <code>make run</code>, I noticed that deleting the my CR (the root object) doesn\'t cause the Deployment sub-resource to get garbage collected. I also noticed that deleting the Deployment sub-resource doesn\'t trigger my reconciler to run. Why is this? Is there something I\'m not doing or is this possibly a limitation of local development/testing?</p>\\n Chris Gillum <p>Using @coderanger\'s hint, I could see that the <code>metadata.ownerReferences</code> weren\'t being set correctly when running the following command:</p>\\n<pre class=""lang-sh prettyprint-override""><code>kubectl get deployments sample-deployment -o yaml\\n</code></pre>\\n<p>The problem was my controller\'s reconcile code. I was calling <code>controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code> only after I\'d already created and persisted the Deployment.</p>\\n<p><strong>Buggy code</strong></p>\\n<pre class=""lang-golang prettyprint-override""><code>log.Info(""Creating a deployment"")\\n\\ndeployment := &appsv1.Deployment{\\n ObjectMeta: metav1.ObjectMeta{\\n Name: deploymentName,\\n Namespace: myResource.Namespace,\\n },\\n Spec: deploymentSpec,\\n}\\n\\nif err = r.Create(ctx, deployment); err != nil {\\n log.Error(err, ""Failed to create deployment"")\\n if errors.IsInvalid(err) {\\n // Don\'t retry on validation errors\\n err = nil\\n }\\n return ctrl.Result{}, err\\n}\\n\\n// Establish the parent-child relationship between my resource and the deployment\\nlog.Info(""Making my resource a parent of the deployment"")\\nif err = controllerutil.SetControllerReference(&myResource, deployment, r.Scheme); err != nil {\\n log.Error(err, ""Failed to set deployment']","To deploy an Okteto environment on Visual Studio Code for Kubernetes development, follow the official steps provided by Okteto. Execute 'Okteto: up' and select the manifest file (e.g., vscode-remote-go/okteto.yml). If you encounter issues such as 'couldn't download syncthing,' ensure that your environment is not behind a proxy, as Okteto does not currently support proxy settings. A workaround is to manually download the syncthing binary and save it as %HOME%\.okteto\syncthing.exe.",single_hop_specifc_query_synthesizer
what microsoft do in kubernetes?,"['controller reference"")\\n return ctrl.Result{}, err\\n}\\n\\n</code></pre>\\n<p>To fix it, I needed to swap the order of the call to <code>r.Create</code> and <code>controllerutil.SetControllerReference</code>:</p>\\n<p><strong>Working code</strong></p>\\n<pre class=""lang-golang prettyprint-override""><code>log.Info(""Creating a deployment"")\\n\\ndeployment := &appsv1.Deployment{\\n ObjectMeta: metav1.ObjectMeta{\\n Name: deploymentName,\\n Namespace: myResource.Namespace,\\n },\\n Spec: deploymentSpec,\\n}\\n\\n// Establish the parent-child relationship between my resource and the deployment\\nlog.Info(""Making my resource a parent of the deployment"")\\nif err = controllerutil.SetControllerReference(&myResource, deployment, r.Scheme); err != nil {\\n log.Error(err, ""Failed to set deployment controller reference"")\\n return ctrl.Result{}, err\\n}\\n\\n// Create the deployment with the parent/child relationship configured\\nif err = r.Create(ctx, deployment); err != nil {\\n log.Error(err, ""Failed to create deployment"")\\n if errors.IsInvalid(err) {\\n // Don\'t retry on validation errors\\n err = nil\\n }\\n return ctrl.Result{}, err\\n}\\n</code></pre>\\n<p>I was able to confirm that this worked by looking at the <code>metadata.ownerReferences</code> YAML data for my created deployment (using the command referenced above).</p>\\n<pre class=""lang-yaml prettyprint-override""><code>apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n annotations:\\n deployment.kubernetes.io/revision: ""1""\\n creationTimestamp: ""2021-08-02T16:22:04Z""\\n generation: 1\\n name: sample-deployment\\n namespace: default\\n ownerReferences:\\n - apiVersion: resources.mydomain.io/v1alpha1\\n blockOwnerDeletion: true\\n controller: true\\n kind: MyResource\\n name: myresource-sample\\n uid: 6ebb146c-afc7-4601-bd75-58efc29beac9\\n resourceVersion: ""569913""\\n uid: d9a4496f-7418-4831-ab87-4804dcd1f8aa\\n</code></pre>\\n Chris Gillum <p>I have deployed Azure Durable Http Triggered Function app in Azure Kubernetes Service. I used Visual Studio Code to create the function app. I have followed instructions from this this <a href=""https://dev.to/anirudhgarg_99/scale-up-and-down-a-http-triggered-function-app-in-kubernetes-using-keda-4m42"" rel=""nofollow noreferrer"">article</a> and <a href=""https://learn.microsoft.com/en-us/azure/azure-functions/functions-kubernetes-keda#deploying-a-function-app-to-kubernetes"" rel=""nofollow noreferrer"">Microsoft official documentation</a>.</p>\\n<pre><code>Function runtime: 3.0.2630\\nPython version: 3.7.7\\nazure-functions: 1.3.1\\nazure-functions-durable: 1.0.0b9\\n</code></pre>\\n<p>Here is my HttStart <code>function.json</code> file looks like,</p>\\n<pre><code>{\\n ""scriptFile"": ""__init__.py"",\\n ""bindings"": [\\n {\\n ""authLevel"": ""anonymous"",\\n ""name"": ""req"",\\n ""type"": ""httpTrigger"",\\n ""direction"": ""in"",\\n ""route"": ""orchestrators/{functionName}"",\\n ""methods"": [\\n ""post"",\\n ""get""\\n ]\\n },\\n {\\n ""name"": ""$return"",\\n ""type"": ""http"",\\n ""direction"": ""out""\\n },\\n {\\n ""name"": ""starter"",\\n ""type"": ""orchestrationClient"",\\n ""direction"": ""in""\\n }\\n ]\\n}\\n</code></pre>\\n<p>Docker file:</p>\\n<pre><code>FROM mcr.microsoft.com/azure-functions/python:3.0-python3.7\\n\\nENV AzureWebJobsScriptRoot=/home/site/wwwroot \\\\n AzureFunctionsJobHost__Logging__Console__IsEnabled=true\\n\\nCOPY requirements.txt /\\nRUN pip install -r /requirements.txt\\n\\nCOPY . /home/site/wwwroot\\n</code></pre>\\n<p>This application works perfectly in my local environment. After deploying to AKS cluster, when I call URL, it throws the following expection</p>\\n<pre><code>fail: Function.HelloWorldHttpStart[3]\\n Executed \'Functions.HelloWorldHttpStart\' (Failed, Id=e7dd35a1-2001-4f11-396f-d251cbd87a0d, Duration=82ms)\\nMicrosoft.Azure.WebJobs.Host.FunctionInvocationException: Exception while executing function: Functions.HelloWorldHttpStart\\n ---> System.InvalidOperationException: Webhooks are not configured\\n at Microsoft.Azure.WebJobs.Extensions.DurableTask.HttpApiHandler.ThrowIfWebhooksNotConfigured() in d:\\a\\r1\\a\\azure-functions-durable-extension\\src\\WebJobs.Extensions.DurableTask\\HttpApiHandler.cs:line 737\\n</code></pre>\\n<p>Is there any configuration I missed out? Any suggestions would be appreciated.</p>\\n<p>Thank you.</p>\\n Shariful Nibir <p>Try adding a <code>WEBSITE_HOSTNAME</code> environment variable with <code><ip-address>:<port></code> as the value, where <code><ip-address>:<port></code> refers to the address that can be used to reach your function app from outside.</p>\\n<p>This error happens when you use an API that depends on this environment variable. When running using the local core tools, this value is set to <code>localhost:7071</code> automatically. When running in the Azure Functions hosted service, this environment variable is also pre-configured to be the DNS name of the function app (e.g. <code>myfunctionapp.azurewebsites.net</code>. For other environments, like AKS, you\'ll need to add this environment variable explicitly and set it to the correct value for your deployment.</p>\\n Chris Gillum <p>Stateless is the way to go for services running in pods however i have been trying to move a stateful app which needs to perform session persistence if one pod goes does for resiliency reasons.</p>\\n\\n<p>In websphere world IHS can be used to keep track of the session and if a node goes down it can be recreated on the live clone. </p>\\n\\n<p>Is there an industry standard way to handle this issue without having to refactor the applications code by persisting the session using some sidecar pod ?</p>\\n Sudheej <p>Yes. Store the session somewhere. Spring boot supports out of the box MongoDB, Redis, Hazelcast or any JDBC database.</p>\\n\\n<blockquote>\\n <p>Spring Boot provides Spring Session auto-configuration for a wide\\n range of data stores. When building a Servlet web application, the\\n following stores can be auto-configured:</p>\\n \\n <p>JDBC Redis Hazelcast MongoDB When building a reactive web application,\\n the following stores can be auto-configured:</p>\\n \\n <p>Redis MongoDB If a single Spring Session module is present on the\\n classpath, Spring Boot uses that store implementation automatically.\\n If you have more than one implementation, you must choose the\\n StoreType that you wish to use to store the sessions. For instance, to\\n use JDBC as the back-end store, you can configure your application as\\n follows:</p>\\n \\n <p>spring.session.store-type=jdbc </p>\\n \\n <p>[Tip] You can disable Spring Session by\\n setting the store-type to none. Each store has specific additional\\n settings. For instance, it is possible to customize the name of the\\n table for the JDBC store, as shown in the following example:</p>\\n \\n <p>spring.session.jdbc.table-name=SESSIONS </p>\\n \\n <p>For setting the timeout of the\\n session you can use the spring.session.timeout property. If that\\n property is not set, the auto-configuration falls back to the value of\\n server.servlet.session.timeout.</p>\\n</blockquote>\\n Strelok <p>I\'m trying to create a simple nginx service on GKE, but I\'m running into strange problems. </p>\\n\\n<p>Nginx runs on port 80 inside the Pod. The service is accessible on port 8080. (This works, I can do <code>curl myservice:8080</code> inside of the pod and see the nginx home screen)</p>\\n\\n<p>But when I try to make it publicly accessible using an ingress, I\'m running into trouble. Here are my deployment, service and ingress files.</p>\\n\\n<pre><code>apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: nginx-deployment\\n labels:\\n app: nginx\\nspec:\\n replicas: 3\\n selector:\\n matchLabels:\\n app: nginx\\n template:\\n metadata:\\n labels:\\n app: nginx\\n spec:\\n containers:\\n - name: nginx\\n image: nginx:1.7.9\\n ports:\\n - containerPort: 80\\n\\n\\nkind: Service\\napiVersion: v1\\nmetadata:\\n name: my-service\\nspec:\\n selector:\\n app: nginx\\n ports:\\n - protocol: TCP\\n port: 8080\\n nodePort: 32111\\n targetPort: 80\\n type: NodePort\\n\\n\\napiVersion: extensions/v1beta1\\nkind: Ingress\\nmetadata:\\n name: test-ingress\\nspec:\\n rules:\\n - http:\\n paths:\\n # The * is needed so that all traffic gets redirected to nginx\\n - path: /*\\n backend:\\n serviceName: my-service\\n servicePort: 80\\n</code></pre>\\n\\n<p>After a while, this is what my ingress status looks like:</p>\\n\\n<pre><code>$ k describe ingress test-ingress\\nName: test-ingress\\nNamespace: default\\nAddress: 35.186.255.184\\nDefault backend: default-http-backend:80 (10.44.1.3:8080)\\nRules:\\n Host Path Backends\\n ---- ---- --------\\n *\\n /* my-service:32111 (<none>)\\nAnnotations:\\n backends: {""k8s-be-30030--ecc76c47732c7f90"":""HEALTHY""}\\n forwarding-rule: k8s-fw-default-test-ingress--ecc76c47732c7f90\\n target-proxy: k8s-tp-default-test-ingress--ecc76c47732c7f90\\n url-map: k8s-um-default-test-ingress--ecc76c47732c7f90\\nEvents:\\n Type Reason Age From Message\\n ---- ------ ---- ---- -------\\n Normal ADD 18m loadbalancer-controller default/test-ingress\\n Normal CREATE 17m loadbalancer-controller ip: 35.186.255.184\\n Warning Service 1m (x5 over 17m) loadbalancer-controller Could not find nodeport for backend {ServiceName:my-service ServicePort:{Type:0 IntVal:32111 StrVal:}}: could not find matching nodeport from service\\n Normal Service 1m (x5 over 17m) loadbalancer-controller no user specified default backend, using system default\\n</code></pre>\\n\\n<p>I don\'t understand why it\'s saying that it can\'t find nodeport - the service has nodePort defined and it is of type NodePort as well. Going to the actual IP results in <code>default backend - 404</code>. </p>\\n\\n<p>Any']",Microsoft provides official documentation for deploying Azure Durable Http Triggered Function apps in Azure Kubernetes Service (AKS).,single_hop_specifc_query_synthesizer
What are Judith's insights on making Apache Ignite zone-aware in Kubernetes?,"['ideas why?</p>\\n Nick <p>The configuration is missing a health check endpoint, for the GKE loadbalancer to know whether the backend is healthy. The <code>containers</code> section for the <code>nginx</code> should also specify:</p>\\n\\n<pre><code> livenessProbe:\\n httpGet:\\n path: /\\n port: 80\\n</code></pre>\\n\\n<p>The <code>GET /</code> on port 80 is the default configuration, and can be changed.</p>\\n Eric Platon <p>I would like to expose my Kubernetes Managed Digital Ocean (single node) cluster\'s service on port 80 without the use of Digital Ocean\'s load balancer. Is this possible? How would I do this? </p>\\n\\n<p>This is essentially a hobby project (I am beginning with Kubernetes) and just want to keep the cost very low. </p>\\n Joseph Horsch <p>You can deploy an Ingress configured to use the host network and port 80/443.</p>\\n<ol>\\n<li><p>DO\'s firewall for your cluster doesn\'t have 80/443 inbound open by default.</p>\\n<p>If you edit the auto-created firewall the rules <a href=""https://www.digitalocean.com/community/questions/how-to-customize-firewall-rules-for-managed-kubernetes-service"" rel=""noreferrer"">will eventually reset themselves</a>. The solution is to create a separate firewall also pointing at the same Kubernetes worker nodes:</p>\\n</li>\\n</ol>\\n<pre><code>$ doctl compute firewall create \\\\n--inbound-rules=""protocol:tcp,ports:80,address:0.0.0.0/0,address:::/0 protocol:tcp,ports:443,address:0.0.0.0/0,address:::/0"" \\\\n--tag-names=k8s:CLUSTER_UUID \\\\n--name=k8s-extra-mycluster\\n</code></pre>\\n<p>(Get the <code>CLUSTER_UUID</code> value from the dashboard or the ID column from <code>doctl kubernetes cluster list</code>)</p>\\n<ol start=""2"">\\n<li>Create the <a href=""https://kubernetes.github.io/ingress-nginx/"" rel=""noreferrer"">nginx ingress</a> using the host network. I\'ve included the <a href=""https://github.com/helm/charts/tree/master/stable/nginx-ingress"" rel=""noreferrer"">helm chart</a> config below, but you could do it via the direct install process too.</li>\\n</ol>\\n<p>EDIT: The Helm chart in the above link has been DEPRECATED, Therefore the correct way of installing the chart would be(<a href=""https://github.com/kubernetes/ingress-nginx/tree/master/charts/ingress-nginx"" rel=""noreferrer"">as per the new docs</a>) is :</p>\\n<pre><code>helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx\\nhelm repo update\\n</code></pre>\\n<p>After this repo is added & updated</p>\\n<pre><code># For Helm 2\\n$ helm install stable/nginx-ingress --name=myingress -f myingress.values.yml\\n\\n# For Helm 3\\n$ helm install myingress stable/nginx-ingress -f myingress.values.yml\\n\\n#EDIT: The New way to install in helm 3\\nhelm install myingress ingress-nginx/ingress-nginx -f myingress.values.yaml\\n</code></pre>\\n<p><code>myingress.values.yml</code> for the chart:</p>\\n<pre class=""lang-yaml prettyprint-override""><code>---\\ncontroller:\\n kind: DaemonSet\\n hostNetwork: true\\n dnsPolicy: ClusterFirstWithHostNet\\n daemonset:\\n useHostPort: true\\n service:\\n type: ClusterIP\\nrbac:\\n create: true\\n</code></pre>\\n<ol start=""3"">\\n<li><p>you should be able to access the cluster on :80 and :443 via any worker node IP and it\'ll route traffic to your ingress.</p>\\n</li>\\n<li><p>since node IPs can & do change, look at deploying <a href=""https://github.com/kubernetes-incubator/external-dns"" rel=""noreferrer"">external-dns</a> to manage DNS entries to point to your worker nodes. Again, using the helm chart and assuming your DNS domain is hosted by DigitalOcean (though any supported DNS provider will work):</p>\\n</li>\\n</ol>\\n<pre><code># For Helm 2\\n$ helm install --name=mydns -f mydns.values.yml stable/external-dns\\n\\n# For Helm 3\\n$ helm install mydns stable/external-dns -f mydns.values.yml\\n</code></pre>\\n<p><code>mydns.values.yml</code> for the chart:</p>\\n<pre class=""lang-yaml prettyprint-override""><code>---\\nprovider: digitalocean\\ndigitalocean:\\n # create the API token at https://cloud.digitalocean.com/account/api/tokens\\n # needs read + write\\n apiToken: ""DIGITALOCEAN_API_TOKEN""\\ndomainFilters:\\n # domains you want external-dns to be able to edit\\n - example.com\\nrbac:\\n create: true\\n</code></pre>\\n<ol start=""5"">\\n<li>create a Kubernetes <a href=""https://kubernetes.github.io/ingress-nginx/user-guide/basic-usage/"" rel=""noreferrer"">Ingress resource</a> to route requests to an existing Kubernetes service:</li>\\n</ol>\\n<pre class=""lang-yaml prettyprint-override""><code>---\\napiVersion: extensions/v1beta1\\nkind: Ingress\\nmetadata:\\n name: testing123-ingress\\n annotations:\\n kubernetes.io/ingress.class: nginx\\nspec:\\n rules:\\n - host: testing123.example.com # the domain you want associated\\n http:\\n paths:\\n - path: /\\n backend:\\n serviceName: testing123-service # existing service\\n servicePort: 8000 # existing service port\\n</code></pre>\\n<ol start=""6"">\\n<li>after a minute or so you should see the DNS records appear and be resolvable:</li>\\n</ol>\\n<pre><code>$ dig testing123.example.com # should return worker IP address\\n$ curl -v http://testing123.example.com # should send the request through the Ingress to your backend service\\n</code></pre>\\n<p>(Edit: editing the automatically created firewall rules eventually breaks, add a separate firewall instead).</p>\\n rcoup <p>The data needs to be loaded periodically (like once in a day), and it should be stored in SQL format so that the API can run SQL queries.\\nWe are thinking of loading it from HDFS. Currently we are thinking of using Apache Nifi using PutIgniteCache. </p>\\n\\n<p>I was thinking probably I can launch a remote Ignite client node and then use IgniteDataStreamer to stream the data, but I was not able to find proper documentation for that. Are there any better ways to do this?</p>\\n sidharth padhee <p>The documentation for Nifi says that <a href=""https://nifi.apache.org/docs/nifi-docs/components/org.apache.nifi/nifi-ignite-nar/1.9.0/org.apache.nifi.processors.ignite.cache.PutIgniteCache/index.html"" rel=""nofollow noreferrer"">it uses the data streamer API</a>, so unless you need more control it doesn’t seem like a bad option (with the caveat that I’d never heard of Nifi before much less used it!).</p>\\n Stephen Darlington <p>Trying Ignite with Kubertenes deployment options. </p>\\n\\n<ol>\\n<li>Is it zone-aware? Cannot find any docs & configuration about this.</li>\\n<li>Can I connect the Kubernetes cluster via an external client? I\'d like to connect via <a href=""https://apacheignite-net.readme.io"" rel=""nofollow noreferrer"">C# client</a>.</li>\\n</ol>\\n\\n<p>Thank you!</p>\\n Judith <ol>\\n<li>Broadly speaking, Ignite assumes all your nodes are close to one another. You could make it aware of multiple zones by using custom affinity functions, but it\'s not straight-forward. There are also third-party solutions (I work for GridGain who provide one) that support data centre replication, etc. that would work in this situation</li>\\n<li>Yes. I would suggest that thick clients should be part of your Kubernetes infrastructure (since they become part of the Ignite cluster topology), but you can connect a thin client just by opening the right ports. You can use Kubernetes load balancing / round robin to connect to any node</li>\\n</ol>\\n Stephen Darlington <p>I am trying to extract podname using the below jq query.</p>\\n<pre class=""lang-sh prettyprint-override""><code>❯ kubectl get pods -l app=mssql-primary --output jsonpath=\'{.items[0].metadata.name}\'\\nmssqlag-primary-deployment-77b8974bb9-dbltl% \\n❯ kubectl get pods -l app=mssql-primary -o json | jq -r \'.items[0].metadata.name\'\\nmssqlag-primary-deployment-77b8974bb9-dbltl\\n</code></pre>\\n<p>While they both provide the same out put the first one has a % character at the end of the pod name. Any reason why ? Is there something wrong with the jsonpath representation in the first command ?</p>\\n Pradeepl <p>I\'m guessing <code>zsh</code> is your shell. The <code>%</code> is an indicator output by your shell to say that the last line output by <code>kubectl</code> had no newline character at the end. So it\'s not <em>extra</em> output, it\'s actually an indicator that the raw <code>kubectl</code> command outputs <em>less</em> than <code>jq</code>.</p>\\n<p>You could explicitly add a newline to the jsonpath output if you want it:</p>\\n<pre><code>kubectl get pods -l app=mssql-primary --output jsonpath=\'{.items[0].metadata.name}{""\\n""}\'\\n</code></pre>\\n<p>Or in the other direction you could tell <code>jq</code> not to add newlines at all by specifying <code>-j</code> instead of <code>-r</code>:</p>\\n<pre><code>kubectl get pods -l app=mssql-primary -o json | jq -j \'.items[0].metadata.name\'\\n</code></pre>\\n Weeble <p>We are trying to use control.sh to activate out Ignite cluster which is running in Kubernetes and has native persistence as described <a href=""https://ignite.apache.org/docs/latest/tools/control-script"" rel=""nofollow noreferrer"">here</a>, however we are getting to']","Judith suggests that while Ignite assumes all nodes are close to one another, it can be made aware of multiple zones by using custom affinity functions. However, this is not straightforward. There are also third-party solutions, such as those provided by GridGain, that support data center replication and could work in this situation.",single_hop_specifc_query_synthesizer
who is Richard Feynman and what he do?,"['error below.</p>\\n<p>We have also tried activating the cluster via the post install of the auto deployment but are getting the same error.</p>\\n<pre><code>lifecycle:\\n postStart:\\n exec:\\n command:\\n - >-\\n /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\n --yes\\n\\n</code></pre>\\n<p>Error:</p>\\n<pre><code>/opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\nfailed - error: command \'/bin/sh -c /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\' exited with 2: , message: ""JVM_OPTS environment variable is set, but will not be used. To pass JVM options use CONTROL_JVM_OPTS\\nJVM_OPTS=-DIGNITE_WAL_MMAP=false -DIGNITE_UPDATE_NOTIFIER=false -XX:+UseG1GC -Xmx4g -XX:+DisableExplicitGC -server -Xms4g -XX:+AlwaysPreTouch -XX:+ScavengeBeforeFullGC\\nControl utility [ver. 2.11.1#20211220-sha1:eae1147d]2021 Copyright(C) Apache Software Foundation\\nUser: root\\nTime: 2022-05-31T18:56:38.690\\nConnection to cluster failed. Latest topology update failed.\\nCommand [SET-STATE] finished with code: 2\\nControl utility has completed execution at: 2022-05-31T18:56:41.859\\nExecution time: 3169 ms\\n</code></pre>\\n RichardFeynman <p>Activating the cluster relates to the lifecycle of the <em>cluster</em> rather than an individual pod, do you don\'t want to add it to the pod.</p>\\n<p>Instead, it\'s a ""manual"" process once all your nodes/pods are up. <a href=""https://medium.com/@sdarlington/activating-an-apache-ignite-cluster-on-kubernetes-afbed40c7e53"" rel=""nofollow noreferrer"">I wrote about it here</a>.</p>\\n<p>In short, either run exec:</p>\\n<pre><code>kubectl exec -it ignite-0 --namespace=ignite -- /opt/ignite/apache-ignite-fabric/bin/control.sh --activate\\n</code></pre>\\n<p>Or create a Kubernetes job.</p>\\n Stephen Darlington <p>Are there any know issues with running the org.apache.ignite.spi.discovery.tcp.ipfinder.kubernetes.TcpDiscoveryKubernetesIpFinder a purely IPv6 environment? I looked <a href=""https://ignite.apache.org/docs/latest/clustering/network-configuration"" rel=""nofollow noreferrer"">here</a> and it mentions there may be issues with clusters becoming detached but does not offer any specifics. Any information would be appreciated, thanks.</p>\\n RichardFeynman <p>I\'m not aware of any IPv6 problems <em>per se</em>, so if your network is configured correctly I would expect it to work.</p>\\n<p>The problem we typically see when IPv6 is enabled is that it\'s possible to route to the IPv4 address but <em>not</em> the IPv6 address -- which is why setting preferIPv4Stack works.</p>\\n Stephen Darlington <p>We have observed following issue when we deploy Ignite Cluster on Open Shift</p>\\n<p>We have created respective PV and PVC YAML files.</p>\\n<p>One more important point is always it points to /ignite/work irrespective of Mount Path.</p>\\n<p>Error details at POD:\\nSLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".\\nSLF4J: Defaulting to no-operation (NOP) logger implementation\\nSLF4J: See <a href=""http://www.slf4j.org/codes.html#StaticLoggerBinder"" rel=""nofollow noreferrer"">http://www.slf4j.org/codes.html#StaticLoggerBinder</a> for further details.\\nclass org.apache.ignite.IgniteException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.convertException(IgniteUtils.java:1135)\\nat org.apache.ignite.Ignition.start(Ignition.java:356)\\nat org.apache.ignite.startup.cmdline.CommandLineStartup.main(CommandLineStartup.java:365)\\nCaused by: class org.apache.ignite.IgniteCheckedException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.workDirectory(IgniteUtils.java:9900)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.initializeConfiguration(IgnitionEx.java:1891)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.start(IgnitionEx.java:1715)\\nat org.apache.ignite.internal.IgnitionEx.start0(IgnitionEx.java:1160)\\nat org.apache.ignite.internal.IgnitionEx.startConfigurations(IgnitionEx.java:1054)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:940)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:839)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:709)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:678)\\nat org.apache.ignite.Ignition.start(Ignition.java:353)\\n... 1 more\\nFailed to start grid: Work directory does not exist and cannot be created: /ignite/work</p>\\n<hr />\\n<p>YAML Content</p>\\n<hr />\\n<p>apiVersion: v1\\nkind: PersistentVolume\\nmetadata:\\nannotations:\\nfield.cattle.io/creatorId: user-zqf4l\\ncreationTimestamp: ""2021-01-12T06:48:02Z""\\nfinalizers:</p>\\n<ul>\\n<li>kubernetes.io/pv-protection\\nlabels:\\ncattle.io/creator: norman\\nname: ignite-storage-work-vol\\nresourceVersion: ""18595579""\\nselfLink: /api/v1/persistentvolumes/newsto\\nuid: ee81855d-6497-4465-abdd-8244883e383b\\nspec:\\naccessModes:</li>\\n<li>ReadWriteOnce\\ncapacity:\\nstorage: 1Gi\\nhostPath:\\n##when you create folder ensure you give proper permission to folder Assing Owner\\n##chown rootadmin:rootadmin grafana\\n##give full writes chmod 777 grafana/\\npath: /opt/work ## Change the location before deploying\\ntype: """"\\npersistentVolumeReclaimPolicy: Retain\\nvolumeMode: Filesystem</li>\\n</ul>\\n<p>.....\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\nname: ignite-storage-work-vol-claim\\nspec:\\nvolumeName: ignite-storage-work-vol\\naccessModes:\\n- ReadWriteOnce\\nresources:\\nrequests:\\nstorage: 1Gi</p>\\n<p>......</p>\\n<h1>An example of a Kubernetes configuration for pod deployment.</h1>\\n<p>apiVersion: apps/v1\\nkind: StatefulSet\\nmetadata:</p>\\n<h1>Cluster name.</h1>\\n<p>name: ignite-cluster\\nnamespace: or\\nspec:</p>\\n<h1>The initial number of Ignite pods.</h1>\\n<p>replicas: 2\\nserviceName: ignite-service\\nselector:\\nmatchLabels:\\napp: ignite\\ntemplate:\\nmetadata:\\nlabels:\\napp: ignite\\nspec:\\nserviceAccountName: ignite\\n# terminationGracePeriodSeconds: 60000 (use in production for graceful restarts and shutdowns)\\ncontainers:\\n# Custom pod name.\\n- name: ignite-node\\nimage: apacheignite/ignite:2.13.0\\nimagePullPolicy: IfNotPresent\\nenv:\\n- name: OPTION_LIBS\\nvalue: ignite-kubernetes,ignite-rest-http\\n- name: CONFIG_URI\\nvalue: file:///ignite/config/ignite-node-cfg.xml\\n- name: JVM_OPTS\\nvalue: ""-DIGNITE_WAL_MMAP=false""\\n# consider this property for production -DIGNITE_WAIT_FOR_BACKUPS_ON_SHUTDOWN=true</p>\\n<pre><code> ports:\\n # Ports you might need to open.\\n - containerPort: 47100 # communication SPI port\\n - containerPort: 47500 # discovery SPI port\\n - containerPort: 49112 # JMX port\\n - containerPort: 10800 # thin clients/JDBC driver port\\n - containerPort: 8080 # REST API\\n volumeMounts:\\n - mountPath: /ignite/config\\n name: config-vol\\n - name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n - name: storage-vol\\n mountPath: /tmp/storage\\n readOnly: false\\n - name: wal-vol \\n mountPath: /tmp/wal\\n readOnly: false\\n - name: walarchive-vol \\n mountPath: /tmp/walarchive\\n readOnly: false\\n \\n\\n volumes:\\n - name: config-vol\\n configMap:\\n name: ignite-cfg-persistent\\n - name: work-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-work-vol-claim\\n - name: storage-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-storage-vol-claim\\n - name: wal-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-wal-vol-claim\\n - name: walarchive-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-walarchive-vol-claim\\n</code></pre>\\n Rameish <p>It\'s expecting to be able to write to <code>/ignite/work</code> but there\'s no persistent volume there. You appear to be mounting them in <code>/tmp</code>. Suggest changing:</p>\\n<pre><code>- name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n</code></pre>\\n<p>To:</p>\\n<pre><code>- name: work-vol\\n mountPath: /ignite/work\\n readOnly: false\\n</code></pre>\\n<p>And the same for the other PVs.</p>\\n Stephen Darlington <p>I am trying to run an ASP.Net docker container on Kubernetes as a non-root user. I have this dockerfile:</p>\\n<pre><code>FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base\\nWORKDIR /app\\nEXPOSE 8443\\n\\nFROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build\\nWORKDIR /src\\nCOPY [""MyProgram.API/MyProgram.API.csproj"", ""MyProgram.API/""]\\nCOPY [""MyProgram.Services/MyProgram.Services.csproj"", ""MyProgram.Services/""]\\nCOPY [""MyProgram.Core/MyProgram.Core.csproj"", ""MyProgram.Core/""]\\nCOPY [""MyProgram.Data/MyProgram.Data.csproj"", ""MyProgram.Data/""]\\nRUN dotnet restore ""MyProgram.API/MyProgram.API.csproj""\\nCOPY . .\\nWORKDIR ""/src/MyProgram.API""\\nRUN dotnet build ""MyProgram.API.csproj"" -c Release -o /app/build\\n\\nFROM build AS publish\\nRUN dotnet publish ""MyProgram.API.csproj"" -c Release -o /app/publish\\n\\nFROM base AS final\\nWORKDIR /app\\nCOPY --from=publish /app/publish .\\nENTRYPOINT [""dotnet"", ""MyProgram.API.dll""]\\n</code></pre>\\n<p>When I run it locally, I can go to https://localhost:8443 and use my app succesfully. When I deploy it to Kubernetes using this file:</p>\\n<pre><code>apiVersion: apps/v1 \\nkind: Deployment\\n# snip\\n spec:\\n securityContext:\\n fsGroup: 2000\\n runAsNonRoot: true\\n runAsUser: 1000\\n containers:\\n - name: myprogram\\n image: mycompany/myprogram:develop\\n imagePullPolicy: ""Always""\\n env:\\n - name: ""ASPNETCORE_ENVIRONMENT""\\n value: ""Kubernetes""\\n ports:\\n - containerPort: 8443\\n name: ""myprogram""\\n securityContext:\\n allowPrivilegeEscalation: false\\n imagePullSecrets:\\n - name: privatereposecret\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\n#snip\\nspec:\\n type: NodePort\\n ports:\\n - protocol: TCP\\n port: 8081\\n targetPort: 8443\\n nodePort: 31999\\n selector:\\n app: myprogram\\n</code></pre>\\n<p>My container won\'t start and gives these gives these log files:</p>\\n<pre><code>[13:13:30 FTL] Unable to start Kestrel.\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n[13:13:30 FTL] Application start-up failed\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Hosting.GenericWebHostService.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.Internal.Host.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.Run(IHost host)\\n at MyProgram.API.Program.Main(String[] args) in /src/MyProgram.API/Program.cs:line 30\\n</code></pre>\\n<p>If I try the exact same deployment without a SecurityContext the container works perfectly. What\'s going wrong?</p>\\n yesman <p>Kestrel is trying to bind to port 80 and/or port 443 because that\'s its default unless you tell it otherwise, and you can\'t do that unless priviledged.</p>\\n<p>You need to specify the ports, usually via environment variables, and']",The context does not provide specific information about Richard Feynman. It only mentions the name 'RichardFeynman' in a user comment without further details.,single_hop_specifc_query_synthesizer
"What are the recommended memory configurations for an Apache Ignite cluster in Kubernetes, and how can persistent volumes be correctly configured to avoid startup errors?","['<1-hop>\n\nQuestion QuestionAuthor Answer AnswerAuthor <p> expose them, e.g.</p>\\n<pre><code># Declare ports above 1024, as an unprivileged non-root user cannot bind to ports <= 1024\\nENV ASPNETCORE_URLS http://+:8000;https://+:8443\\nEXPOSE 8000\\nEXPOSE 8443\\n</code></pre>\\n blowdart <p>I have a Kubernetes setup of 7 Apache Ignite servers and over 100 clients.</p>\\n\\n<p>With my current Apache Ignite configuration, I am seeing the following line of log for the servers:</p>\\n\\n<pre><code>java.lang.OutOfMemoryError: Java heap space\\n</code></pre>\\n\\n<p>Below is the memory configuration Apache Ignite server:</p>\\n\\n<ul>\\n<li>Pod memory limit: 2Gb</li>\\n<li>Xmx: 768m</li>\\n</ul>\\n\\n<p>I would like to know what should be the optimum Memory configuration for the Apache Ignite cluster</p>\\n ho wing kent <p>It depends on what you\'re trying to do -- persistence and SQL tend to use more heap space for example -- but both 2Gb and 768Mb are <em>much</em> smaller than I\'d expect for an in-memory database.</p>\\n\\n<p>The <a href=""https://www.gridgain.com/docs/latest/perf-troubleshooting-guide/memory-tuning"" rel=""nofollow noreferrer"">tuning guide</a> suggests 10Gb as a starting point:</p>\\n\\n<pre><code>-server\\n-Xms10g\\n-Xmx10g\\n-XX:+AlwaysPreTouch\\n-XX:+UseG1GC\\n-XX:+ScavengeBeforeFullGC\\n-XX:+DisableExplicitGC\\n</code></pre>\\n Stephen Darlington', '<2-hop>\n\nerror below.</p>\\n<p>We have also tried activating the cluster via the post install of the auto deployment but are getting the same error.</p>\\n<pre><code>lifecycle:\\n postStart:\\n exec:\\n command:\\n - >-\\n /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\n --yes\\n\\n</code></pre>\\n<p>Error:</p>\\n<pre><code>/opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\nfailed - error: command \'/bin/sh -c /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\' exited with 2: , message: ""JVM_OPTS environment variable is set, but will not be used. To pass JVM options use CONTROL_JVM_OPTS\\nJVM_OPTS=-DIGNITE_WAL_MMAP=false -DIGNITE_UPDATE_NOTIFIER=false -XX:+UseG1GC -Xmx4g -XX:+DisableExplicitGC -server -Xms4g -XX:+AlwaysPreTouch -XX:+ScavengeBeforeFullGC\\nControl utility [ver. 2.11.1#20211220-sha1:eae1147d]2021 Copyright(C) Apache Software Foundation\\nUser: root\\nTime: 2022-05-31T18:56:38.690\\nConnection to cluster failed. Latest topology update failed.\\nCommand [SET-STATE] finished with code: 2\\nControl utility has completed execution at: 2022-05-31T18:56:41.859\\nExecution time: 3169 ms\\n</code></pre>\\n RichardFeynman <p>Activating the cluster relates to the lifecycle of the <em>cluster</em> rather than an individual pod, do you don\'t want to add it to the pod.</p>\\n<p>Instead, it\'s a ""manual"" process once all your nodes/pods are up. <a href=""https://medium.com/@sdarlington/activating-an-apache-ignite-cluster-on-kubernetes-afbed40c7e53"" rel=""nofollow noreferrer"">I wrote about it here</a>.</p>\\n<p>In short, either run exec:</p>\\n<pre><code>kubectl exec -it ignite-0 --namespace=ignite -- /opt/ignite/apache-ignite-fabric/bin/control.sh --activate\\n</code></pre>\\n<p>Or create a Kubernetes job.</p>\\n Stephen Darlington <p>Are there any know issues with running the org.apache.ignite.spi.discovery.tcp.ipfinder.kubernetes.TcpDiscoveryKubernetesIpFinder a purely IPv6 environment? I looked <a href=""https://ignite.apache.org/docs/latest/clustering/network-configuration"" rel=""nofollow noreferrer"">here</a> and it mentions there may be issues with clusters becoming detached but does not offer any specifics. Any information would be appreciated, thanks.</p>\\n RichardFeynman <p>I\'m not aware of any IPv6 problems <em>per se</em>, so if your network is configured correctly I would expect it to work.</p>\\n<p>The problem we typically see when IPv6 is enabled is that it\'s possible to route to the IPv4 address but <em>not</em> the IPv6 address -- which is why setting preferIPv4Stack works.</p>\\n Stephen Darlington <p>We have observed following issue when we deploy Ignite Cluster on Open Shift</p>\\n<p>We have created respective PV and PVC YAML files.</p>\\n<p>One more important point is always it points to /ignite/work irrespective of Mount Path.</p>\\n<p>Error details at POD:\\nSLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".\\nSLF4J: Defaulting to no-operation (NOP) logger implementation\\nSLF4J: See <a href=""http://www.slf4j.org/codes.html#StaticLoggerBinder"" rel=""nofollow noreferrer"">http://www.slf4j.org/codes.html#StaticLoggerBinder</a> for further details.\\nclass org.apache.ignite.IgniteException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.convertException(IgniteUtils.java:1135)\\nat org.apache.ignite.Ignition.start(Ignition.java:356)\\nat org.apache.ignite.startup.cmdline.CommandLineStartup.main(CommandLineStartup.java:365)\\nCaused by: class org.apache.ignite.IgniteCheckedException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.workDirectory(IgniteUtils.java:9900)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.initializeConfiguration(IgnitionEx.java:1891)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.start(IgnitionEx.java:1715)\\nat org.apache.ignite.internal.IgnitionEx.start0(IgnitionEx.java:1160)\\nat org.apache.ignite.internal.IgnitionEx.startConfigurations(IgnitionEx.java:1054)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:940)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:839)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:709)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:678)\\nat org.apache.ignite.Ignition.start(Ignition.java:353)\\n... 1 more\\nFailed to start grid: Work directory does not exist and cannot be created: /ignite/work</p>\\n<hr />\\n<p>YAML Content</p>\\n<hr />\\n<p>apiVersion: v1\\nkind: PersistentVolume\\nmetadata:\\nannotations:\\nfield.cattle.io/creatorId: user-zqf4l\\ncreationTimestamp: ""2021-01-12T06:48:02Z""\\nfinalizers:</p>\\n<ul>\\n<li>kubernetes.io/pv-protection\\nlabels:\\ncattle.io/creator: norman\\nname: ignite-storage-work-vol\\nresourceVersion: ""18595579""\\nselfLink: /api/v1/persistentvolumes/newsto\\nuid: ee81855d-6497-4465-abdd-8244883e383b\\nspec:\\naccessModes:</li>\\n<li>ReadWriteOnce\\ncapacity:\\nstorage: 1Gi\\nhostPath:\\n##when you create folder ensure you give proper permission to folder Assing Owner\\n##chown rootadmin:rootadmin grafana\\n##give full writes chmod 777 grafana/\\npath: /opt/work ## Change the location before deploying\\ntype: """"\\npersistentVolumeReclaimPolicy: Retain\\nvolumeMode: Filesystem</li>\\n</ul>\\n<p>.....\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\nname: ignite-storage-work-vol-claim\\nspec:\\nvolumeName: ignite-storage-work-vol\\naccessModes:\\n- ReadWriteOnce\\nresources:\\nrequests:\\nstorage: 1Gi</p>\\n<p>......</p>\\n<h1>An example of a Kubernetes configuration for pod deployment.</h1>\\n<p>apiVersion: apps/v1\\nkind: StatefulSet\\nmetadata:</p>\\n<h1>Cluster name.</h1>\\n<p>name: ignite-cluster\\nnamespace: or\\nspec:</p>\\n<h1>The initial number of Ignite pods.</h1>\\n<p>replicas: 2\\nserviceName: ignite-service\\nselector:\\nmatchLabels:\\napp: ignite\\ntemplate:\\nmetadata:\\nlabels:\\napp: ignite\\nspec:\\nserviceAccountName: ignite\\n# terminationGracePeriodSeconds: 60000 (use in production for graceful restarts and shutdowns)\\ncontainers:\\n# Custom pod name.\\n- name: ignite-node\\nimage: apacheignite/ignite:2.13.0\\nimagePullPolicy: IfNotPresent\\nenv:\\n- name: OPTION_LIBS\\nvalue: ignite-kubernetes,ignite-rest-http\\n- name: CONFIG_URI\\nvalue: file:///ignite/config/ignite-node-cfg.xml\\n- name: JVM_OPTS\\nvalue: ""-DIGNITE_WAL_MMAP=false""\\n# consider this property for production -DIGNITE_WAIT_FOR_BACKUPS_ON_SHUTDOWN=true</p>\\n<pre><code> ports:\\n # Ports you might need to open.\\n - containerPort: 47100 # communication SPI port\\n - containerPort: 47500 # discovery SPI port\\n - containerPort: 49112 # JMX port\\n - containerPort: 10800 # thin clients/JDBC driver port\\n - containerPort: 8080 # REST API\\n volumeMounts:\\n - mountPath: /ignite/config\\n name: config-vol\\n - name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n - name: storage-vol\\n mountPath: /tmp/storage\\n readOnly: false\\n - name: wal-vol \\n mountPath: /tmp/wal\\n readOnly: false\\n - name: walarchive-vol \\n mountPath: /tmp/walarchive\\n readOnly: false\\n \\n\\n volumes:\\n - name: config-vol\\n configMap:\\n name: ignite-cfg-persistent\\n - name: work-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-work-vol-claim\\n - name: storage-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-storage-vol-claim\\n - name: wal-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-wal-vol-claim\\n - name: walarchive-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-walarchive-vol-claim\\n</code></pre>\\n Rameish <p>It\'s expecting to be able to write to <code>/ignite/work</code> but there\'s no persistent volume there. You appear to be mounting them in <code>/tmp</code>. Suggest changing:</p>\\n<pre><code>- name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n</code></pre>\\n<p>To:</p>\\n<pre><code>- name: work-vol\\n mountPath: /ignite/work\\n readOnly: false\\n</code></pre>\\n<p>And the same for the other PVs.</p>\\n Stephen Darlington <p>I am trying to run an ASP.Net docker container on Kubernetes as a non-root user. I have this dockerfile:</p>\\n<pre><code>FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base\\nWORKDIR /app\\nEXPOSE 8443\\n\\nFROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build\\nWORKDIR /src\\nCOPY [""MyProgram.API/MyProgram.API.csproj"", ""MyProgram.API/""]\\nCOPY [""MyProgram.Services/MyProgram.Services.csproj"", ""MyProgram.Services/""]\\nCOPY [""MyProgram.Core/MyProgram.Core.csproj"", ""MyProgram.Core/""]\\nCOPY [""MyProgram.Data/MyProgram.Data.csproj"", ""MyProgram.Data/""]\\nRUN dotnet restore ""MyProgram.API/MyProgram.API.csproj""\\nCOPY . .\\nWORKDIR ""/src/MyProgram.API""\\nRUN dotnet build ""MyProgram.API.csproj"" -c Release -o /app/build\\n\\nFROM build AS publish\\nRUN dotnet publish ""MyProgram.API.csproj"" -c Release -o /app/publish\\n\\nFROM base AS final\\nWORKDIR /app\\nCOPY --from=publish /app/publish .\\nENTRYPOINT [""dotnet"", ""MyProgram.API.dll""]\\n</code></pre>\\n<p>When I run it locally, I can go to https://localhost:8443 and use my app succesfully. When I deploy it to Kubernetes using this file:</p>\\n<pre><code>apiVersion: apps/v1 \\nkind: Deployment\\n# snip\\n spec:\\n securityContext:\\n fsGroup: 2000\\n runAsNonRoot: true\\n runAsUser: 1000\\n containers:\\n - name: myprogram\\n image: mycompany/myprogram:develop\\n imagePullPolicy: ""Always""\\n env:\\n - name: ""ASPNETCORE_ENVIRONMENT""\\n value: ""Kubernetes""\\n ports:\\n - containerPort: 8443\\n name: ""myprogram""\\n securityContext:\\n allowPrivilegeEscalation: false\\n imagePullSecrets:\\n - name: privatereposecret\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\n#snip\\nspec:\\n type: NodePort\\n ports:\\n - protocol: TCP\\n port: 8081\\n targetPort: 8443\\n nodePort: 31999\\n selector:\\n app: myprogram\\n</code></pre>\\n<p>My container won\'t start and gives these gives these log files:</p>\\n<pre><code>[13:13:30 FTL] Unable to start Kestrel.\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n[13:13:30 FTL] Application start-up failed\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Hosting.GenericWebHostService.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.Internal.Host.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.Run(IHost host)\\n at MyProgram.API.Program.Main(String[] args) in /src/MyProgram.API/Program.cs:line 30\\n</code></pre>\\n<p>If I try the exact same deployment without a SecurityContext the container works perfectly. What\'s going wrong?</p>\\n yesman <p>Kestrel is trying to bind to port 80 and/or port 443 because that\'s its default unless you tell it otherwise, and you can\'t do that unless priviledged.</p>\\n<p>You need to specify the ports, usually via environment variables, and']","For an Apache Ignite cluster in Kubernetes, the recommended memory configuration is to start with 10Gb for both Xms and Xmx, as smaller configurations like 2Gb and 768Mb are much smaller than expected for an in-memory database. This can be set using JVM options such as -Xms10g and -Xmx10g. Additionally, to avoid startup errors related to persistent volumes, ensure that the work directory is correctly mounted. The persistent volume should be mounted to /ignite/work instead of /tmp/work, as the Ignite cluster expects to write to /ignite/work. This adjustment in the Kubernetes configuration will help prevent errors related to the work directory not existing or being inaccessible.",multi_hop_specific_query_synthesizer
"What are the recommended memory configurations for an Apache Ignite cluster in Kubernetes, and how can issues related to persistent volumes and cluster activation be addressed?","['<1-hop>\n\nQuestion QuestionAuthor Answer AnswerAuthor <p> expose them, e.g.</p>\\n<pre><code># Declare ports above 1024, as an unprivileged non-root user cannot bind to ports <= 1024\\nENV ASPNETCORE_URLS http://+:8000;https://+:8443\\nEXPOSE 8000\\nEXPOSE 8443\\n</code></pre>\\n blowdart <p>I have a Kubernetes setup of 7 Apache Ignite servers and over 100 clients.</p>\\n\\n<p>With my current Apache Ignite configuration, I am seeing the following line of log for the servers:</p>\\n\\n<pre><code>java.lang.OutOfMemoryError: Java heap space\\n</code></pre>\\n\\n<p>Below is the memory configuration Apache Ignite server:</p>\\n\\n<ul>\\n<li>Pod memory limit: 2Gb</li>\\n<li>Xmx: 768m</li>\\n</ul>\\n\\n<p>I would like to know what should be the optimum Memory configuration for the Apache Ignite cluster</p>\\n ho wing kent <p>It depends on what you\'re trying to do -- persistence and SQL tend to use more heap space for example -- but both 2Gb and 768Mb are <em>much</em> smaller than I\'d expect for an in-memory database.</p>\\n\\n<p>The <a href=""https://www.gridgain.com/docs/latest/perf-troubleshooting-guide/memory-tuning"" rel=""nofollow noreferrer"">tuning guide</a> suggests 10Gb as a starting point:</p>\\n\\n<pre><code>-server\\n-Xms10g\\n-Xmx10g\\n-XX:+AlwaysPreTouch\\n-XX:+UseG1GC\\n-XX:+ScavengeBeforeFullGC\\n-XX:+DisableExplicitGC\\n</code></pre>\\n Stephen Darlington', '<2-hop>\n\nerror below.</p>\\n<p>We have also tried activating the cluster via the post install of the auto deployment but are getting the same error.</p>\\n<pre><code>lifecycle:\\n postStart:\\n exec:\\n command:\\n - >-\\n /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\n --yes\\n\\n</code></pre>\\n<p>Error:</p>\\n<pre><code>/opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\\nfailed - error: command \'/bin/sh -c /opt/ignite/apache-ignite/bin/control.sh --set-state ACTIVE\' exited with 2: , message: ""JVM_OPTS environment variable is set, but will not be used. To pass JVM options use CONTROL_JVM_OPTS\\nJVM_OPTS=-DIGNITE_WAL_MMAP=false -DIGNITE_UPDATE_NOTIFIER=false -XX:+UseG1GC -Xmx4g -XX:+DisableExplicitGC -server -Xms4g -XX:+AlwaysPreTouch -XX:+ScavengeBeforeFullGC\\nControl utility [ver. 2.11.1#20211220-sha1:eae1147d]2021 Copyright(C) Apache Software Foundation\\nUser: root\\nTime: 2022-05-31T18:56:38.690\\nConnection to cluster failed. Latest topology update failed.\\nCommand [SET-STATE] finished with code: 2\\nControl utility has completed execution at: 2022-05-31T18:56:41.859\\nExecution time: 3169 ms\\n</code></pre>\\n RichardFeynman <p>Activating the cluster relates to the lifecycle of the <em>cluster</em> rather than an individual pod, do you don\'t want to add it to the pod.</p>\\n<p>Instead, it\'s a ""manual"" process once all your nodes/pods are up. <a href=""https://medium.com/@sdarlington/activating-an-apache-ignite-cluster-on-kubernetes-afbed40c7e53"" rel=""nofollow noreferrer"">I wrote about it here</a>.</p>\\n<p>In short, either run exec:</p>\\n<pre><code>kubectl exec -it ignite-0 --namespace=ignite -- /opt/ignite/apache-ignite-fabric/bin/control.sh --activate\\n</code></pre>\\n<p>Or create a Kubernetes job.</p>\\n Stephen Darlington <p>Are there any know issues with running the org.apache.ignite.spi.discovery.tcp.ipfinder.kubernetes.TcpDiscoveryKubernetesIpFinder a purely IPv6 environment? I looked <a href=""https://ignite.apache.org/docs/latest/clustering/network-configuration"" rel=""nofollow noreferrer"">here</a> and it mentions there may be issues with clusters becoming detached but does not offer any specifics. Any information would be appreciated, thanks.</p>\\n RichardFeynman <p>I\'m not aware of any IPv6 problems <em>per se</em>, so if your network is configured correctly I would expect it to work.</p>\\n<p>The problem we typically see when IPv6 is enabled is that it\'s possible to route to the IPv4 address but <em>not</em> the IPv6 address -- which is why setting preferIPv4Stack works.</p>\\n Stephen Darlington <p>We have observed following issue when we deploy Ignite Cluster on Open Shift</p>\\n<p>We have created respective PV and PVC YAML files.</p>\\n<p>One more important point is always it points to /ignite/work irrespective of Mount Path.</p>\\n<p>Error details at POD:\\nSLF4J: Failed to load class ""org.slf4j.impl.StaticLoggerBinder"".\\nSLF4J: Defaulting to no-operation (NOP) logger implementation\\nSLF4J: See <a href=""http://www.slf4j.org/codes.html#StaticLoggerBinder"" rel=""nofollow noreferrer"">http://www.slf4j.org/codes.html#StaticLoggerBinder</a> for further details.\\nclass org.apache.ignite.IgniteException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.convertException(IgniteUtils.java:1135)\\nat org.apache.ignite.Ignition.start(Ignition.java:356)\\nat org.apache.ignite.startup.cmdline.CommandLineStartup.main(CommandLineStartup.java:365)\\nCaused by: class org.apache.ignite.IgniteCheckedException: Work directory does not exist and cannot be created: /ignite/work\\nat org.apache.ignite.internal.util.IgniteUtils.workDirectory(IgniteUtils.java:9900)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.initializeConfiguration(IgnitionEx.java:1891)\\nat org.apache.ignite.internal.IgnitionEx$IgniteNamedInstance.start(IgnitionEx.java:1715)\\nat org.apache.ignite.internal.IgnitionEx.start0(IgnitionEx.java:1160)\\nat org.apache.ignite.internal.IgnitionEx.startConfigurations(IgnitionEx.java:1054)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:940)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:839)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:709)\\nat org.apache.ignite.internal.IgnitionEx.start(IgnitionEx.java:678)\\nat org.apache.ignite.Ignition.start(Ignition.java:353)\\n... 1 more\\nFailed to start grid: Work directory does not exist and cannot be created: /ignite/work</p>\\n<hr />\\n<p>YAML Content</p>\\n<hr />\\n<p>apiVersion: v1\\nkind: PersistentVolume\\nmetadata:\\nannotations:\\nfield.cattle.io/creatorId: user-zqf4l\\ncreationTimestamp: ""2021-01-12T06:48:02Z""\\nfinalizers:</p>\\n<ul>\\n<li>kubernetes.io/pv-protection\\nlabels:\\ncattle.io/creator: norman\\nname: ignite-storage-work-vol\\nresourceVersion: ""18595579""\\nselfLink: /api/v1/persistentvolumes/newsto\\nuid: ee81855d-6497-4465-abdd-8244883e383b\\nspec:\\naccessModes:</li>\\n<li>ReadWriteOnce\\ncapacity:\\nstorage: 1Gi\\nhostPath:\\n##when you create folder ensure you give proper permission to folder Assing Owner\\n##chown rootadmin:rootadmin grafana\\n##give full writes chmod 777 grafana/\\npath: /opt/work ## Change the location before deploying\\ntype: """"\\npersistentVolumeReclaimPolicy: Retain\\nvolumeMode: Filesystem</li>\\n</ul>\\n<p>.....\\napiVersion: v1\\nkind: PersistentVolumeClaim\\nmetadata:\\nname: ignite-storage-work-vol-claim\\nspec:\\nvolumeName: ignite-storage-work-vol\\naccessModes:\\n- ReadWriteOnce\\nresources:\\nrequests:\\nstorage: 1Gi</p>\\n<p>......</p>\\n<h1>An example of a Kubernetes configuration for pod deployment.</h1>\\n<p>apiVersion: apps/v1\\nkind: StatefulSet\\nmetadata:</p>\\n<h1>Cluster name.</h1>\\n<p>name: ignite-cluster\\nnamespace: or\\nspec:</p>\\n<h1>The initial number of Ignite pods.</h1>\\n<p>replicas: 2\\nserviceName: ignite-service\\nselector:\\nmatchLabels:\\napp: ignite\\ntemplate:\\nmetadata:\\nlabels:\\napp: ignite\\nspec:\\nserviceAccountName: ignite\\n# terminationGracePeriodSeconds: 60000 (use in production for graceful restarts and shutdowns)\\ncontainers:\\n# Custom pod name.\\n- name: ignite-node\\nimage: apacheignite/ignite:2.13.0\\nimagePullPolicy: IfNotPresent\\nenv:\\n- name: OPTION_LIBS\\nvalue: ignite-kubernetes,ignite-rest-http\\n- name: CONFIG_URI\\nvalue: file:///ignite/config/ignite-node-cfg.xml\\n- name: JVM_OPTS\\nvalue: ""-DIGNITE_WAL_MMAP=false""\\n# consider this property for production -DIGNITE_WAIT_FOR_BACKUPS_ON_SHUTDOWN=true</p>\\n<pre><code> ports:\\n # Ports you might need to open.\\n - containerPort: 47100 # communication SPI port\\n - containerPort: 47500 # discovery SPI port\\n - containerPort: 49112 # JMX port\\n - containerPort: 10800 # thin clients/JDBC driver port\\n - containerPort: 8080 # REST API\\n volumeMounts:\\n - mountPath: /ignite/config\\n name: config-vol\\n - name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n - name: storage-vol\\n mountPath: /tmp/storage\\n readOnly: false\\n - name: wal-vol \\n mountPath: /tmp/wal\\n readOnly: false\\n - name: walarchive-vol \\n mountPath: /tmp/walarchive\\n readOnly: false\\n \\n\\n volumes:\\n - name: config-vol\\n configMap:\\n name: ignite-cfg-persistent\\n - name: work-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-work-vol-claim\\n - name: storage-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-storage-vol-claim\\n - name: wal-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-wal-vol-claim\\n - name: walarchive-vol\\n persistentVolumeClaim:\\n claimName: ignite-storage-walarchive-vol-claim\\n</code></pre>\\n Rameish <p>It\'s expecting to be able to write to <code>/ignite/work</code> but there\'s no persistent volume there. You appear to be mounting them in <code>/tmp</code>. Suggest changing:</p>\\n<pre><code>- name: work-vol\\n mountPath: /tmp/work\\n readOnly: false\\n</code></pre>\\n<p>To:</p>\\n<pre><code>- name: work-vol\\n mountPath: /ignite/work\\n readOnly: false\\n</code></pre>\\n<p>And the same for the other PVs.</p>\\n Stephen Darlington <p>I am trying to run an ASP.Net docker container on Kubernetes as a non-root user. I have this dockerfile:</p>\\n<pre><code>FROM mcr.microsoft.com/dotnet/core/aspnet:3.1-buster-slim AS base\\nWORKDIR /app\\nEXPOSE 8443\\n\\nFROM mcr.microsoft.com/dotnet/core/sdk:3.1-buster AS build\\nWORKDIR /src\\nCOPY [""MyProgram.API/MyProgram.API.csproj"", ""MyProgram.API/""]\\nCOPY [""MyProgram.Services/MyProgram.Services.csproj"", ""MyProgram.Services/""]\\nCOPY [""MyProgram.Core/MyProgram.Core.csproj"", ""MyProgram.Core/""]\\nCOPY [""MyProgram.Data/MyProgram.Data.csproj"", ""MyProgram.Data/""]\\nRUN dotnet restore ""MyProgram.API/MyProgram.API.csproj""\\nCOPY . .\\nWORKDIR ""/src/MyProgram.API""\\nRUN dotnet build ""MyProgram.API.csproj"" -c Release -o /app/build\\n\\nFROM build AS publish\\nRUN dotnet publish ""MyProgram.API.csproj"" -c Release -o /app/publish\\n\\nFROM base AS final\\nWORKDIR /app\\nCOPY --from=publish /app/publish .\\nENTRYPOINT [""dotnet"", ""MyProgram.API.dll""]\\n</code></pre>\\n<p>When I run it locally, I can go to https://localhost:8443 and use my app succesfully. When I deploy it to Kubernetes using this file:</p>\\n<pre><code>apiVersion: apps/v1 \\nkind: Deployment\\n# snip\\n spec:\\n securityContext:\\n fsGroup: 2000\\n runAsNonRoot: true\\n runAsUser: 1000\\n containers:\\n - name: myprogram\\n image: mycompany/myprogram:develop\\n imagePullPolicy: ""Always""\\n env:\\n - name: ""ASPNETCORE_ENVIRONMENT""\\n value: ""Kubernetes""\\n ports:\\n - containerPort: 8443\\n name: ""myprogram""\\n securityContext:\\n allowPrivilegeEscalation: false\\n imagePullSecrets:\\n - name: privatereposecret\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\n#snip\\nspec:\\n type: NodePort\\n ports:\\n - protocol: TCP\\n port: 8081\\n targetPort: 8443\\n nodePort: 31999\\n selector:\\n app: myprogram\\n</code></pre>\\n<p>My container won\'t start and gives these gives these log files:</p>\\n<pre><code>[13:13:30 FTL] Unable to start Kestrel.\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n[13:13:30 FTL] Application start-up failed\\nSystem.Net.Sockets.SocketException (13): Permission denied\\n at System.Net.Sockets.Socket.UpdateStatusAfterSocketErrorAndThrowException(SocketError error, String callerName)\\n at System.Net.Sockets.Socket.DoBind(EndPoint endPointSnapshot, SocketAddress socketAddress)\\n at System.Net.Sockets.Socket.Bind(EndPoint localEP)\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketConnectionListener.Bind()\\n at Microsoft.AspNetCore.Server.Kestrel.Transport.Sockets.SocketTransportFactory.BindAsync(EndPoint endpoint, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.<>c__DisplayClass21_0`1.<<StartAsync>g__OnBind|0>d.MoveNext()\\n--- End of stack trace from previous location where exception was thrown ---\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindEndpointAsync(ListenOptions endpoint, AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.ListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.AnyIPListenOptions.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.AddressesStrategy.BindAsync(AddressBindContext context)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.Internal.AddressBinder.BindAsync(IServerAddressesFeature addresses, KestrelServerOptions serverOptions, ILogger logger, Func`2 createBinding)\\n at Microsoft.AspNetCore.Server.Kestrel.Core.KestrelServer.StartAsync[TContext](IHttpApplication`1 application, CancellationToken cancellationToken)\\n at Microsoft.AspNetCore.Hosting.GenericWebHostService.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.Internal.Host.StartAsync(CancellationToken cancellationToken)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.RunAsync(IHost host, CancellationToken token)\\n at Microsoft.Extensions.Hosting.HostingAbstractionsHostExtensions.Run(IHost host)\\n at MyProgram.API.Program.Main(String[] args) in /src/MyProgram.API/Program.cs:line 30\\n</code></pre>\\n<p>If I try the exact same deployment without a SecurityContext the container works perfectly. What\'s going wrong?</p>\\n yesman <p>Kestrel is trying to bind to port 80 and/or port 443 because that\'s its default unless you tell it otherwise, and you can\'t do that unless priviledged.</p>\\n<p>You need to specify the ports, usually via environment variables, and']","For an Apache Ignite cluster in Kubernetes, the recommended memory configuration is significantly higher than the initial setup of 2Gb pod memory limit and 768Mb Xmx, which are much smaller than expected for an in-memory database. The tuning guide suggests starting with 10Gb for both Xms and Xmx. Additionally, issues related to persistent volumes can be addressed by ensuring that the work directory is correctly mounted. For example, the work volume should be mounted to /ignite/work instead of /tmp/work to avoid errors related to the work directory not existing. Regarding cluster activation, it should be a manual process once all nodes/pods are up, rather than being added to the pod lifecycle. This can be done by running a command like 'kubectl exec -it ignite-0 --namespace=ignite -- /opt/ignite/apache-ignite-fabric/bin/control.sh --activate' or by creating a Kubernetes job.",multi_hop_specific_query_synthesizer
"What are the challenges and solutions for deploying applications using Okteto in a Kubernetes environment, particularly when dealing with proxies and private image pulls?","['<1-hop>\n\nS3. I see that some Kubernetes setups use a kind of shared volume defined by a git repository, that might also work. Airflow itself (the webserver(s), worker(s), nor scheduler) does not offer any hook to upload into the DAG directory.</p>\\n dlamblin <p>I\'m trying to deploy okteto environment on Visual Studio Code to use Remote Development on Kubernetes.</p>\\n<p>Following the official steps (<a href=""https://okteto.com/blog/remote-kubernetes-development/"" rel=""nofollow noreferrer"">https://okteto.com/blog/remote-kubernetes-development/</a>), I executed ""Okteto: up"" and selected manifest(vscode-remote-go/okteto.yml), but got this error:</p>\\n<pre><code>Installing dependencies... \\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>By changing the log level, I also got these logs:</p>\\n<pre><code>C:\\Users\\user\\AppData\\Local\\Programs\\okteto.exe up -f \'c:\\Workspace\\...my_project...\\vscode-remote-go\\okteto.yml\' --remote \'22100\' --loglevel=debug\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""starting up command""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to get latest version from github: fail to get releases from github: Get \\""https://api.github.com/repos/okteto/okteto/releases?per_page=5\\"": dial tcp: lookup api.github.com: no such host""\\nInstalling dependencies...\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""failed to upgrade syncthing: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""couldn\'t download syncthing, please try again""\\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>This environment is behind my corporate proxy, and okteto.exe may not use Windows proxy setting. When I directly enter the URL (<a href=""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip"" rel=""nofollow noreferrer"">https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip</a>) it can be downloaded using proxy.</p>\\n<p>Is it possible to use okteto behind proxy?</p>\\n Daigo <p>Using a proxy is not currently supported in the Okteto. We\'re looking into it though.</p>\\n<p>For now, a workaround is to manually download the syncthing binary and save it as<code>%HOME%\\.okteto\\syncthing.exe</code></p>\\n Ramiro Berrelleza <p>Is there currently a way to serve websockets from an application deployed on Okteto cloud given the okteto-specific limitations around <code>Ingress</code>es and <code>Service</code>s ?</p>\\n\\n<hr>\\n\\n<p>I\'ve read that this would only be possible using a <code>Service</code> or <code>Ingress</code> of type <code>LoadBalancer</code>, so that is what I\'ve tried.</p>\\n\\n<p>But, according to the <a href=""https://okteto.com/docs/cloud/build"" rel=""nofollow noreferrer"">Okteto docs</a>, <code>Service</code>s of type <code>LoadBalancer</code> (or <code>NodePort</code>) are managed. In practice they seem to get transformed automatically into a <code>ClusterIP Service</code>, + exposed to the internet on an automatic URL.</p>\\n\\n<p>Do these handle only <code>HTTP</code> requests ? Or is there a way to make them handle other kinds of connections based on TCP or UDP (like websockets) ?</p>\\n Nicolas Marshall <p>You don\'t need a LoadBalancer to use WebSockets, they can be served from an Ingress with a ClusterIP as well (this is what Okteto Cloud uses for our endpoints). This setup supports HTTPS, WebSockets and even GRPC-based endpoints.</p>\\n\\n<p><a href=""https://github.com/okteto/node-websocket"" rel=""nofollow noreferrer"">This sample</a> shows you how to use WebSockets on a Node app deployed in Okteto Cloud, hope it helps! (it uses okteto-generated Kubernetes manifests, but you can also bring your own).</p>\\n Ramiro Berrelleza <p>I was working on Jenkins for many days and deploy my services to Kubernetes.</p>\\n\\n<p>I recently came across Jenkins X, I also found a Helm chart for Jenkins through which I can host Jenkins in Kubernetes. Now I\'m confused if they both are same?</p>\\n RohithVallabhaneni <p>No they are different. I assume the helm chart you found installs and configure Jenkins on Kubernetes - perhaps configured with some agents to run builds. </p>\\n\\n<p>Jenkins X is a kubernetes native implementation of CI/CD, it uses some components of Jenkins, but has a lot more to it (for example, applications, environments, review apps, deployments and so on) for running apps ON kubernetes in a CI/CD fashion. The Jenkins helm chart likely sets up a single server. </p>\\n\\n<p>edit: in the time since, Jenkins X has evolved a lot. It is now build using he Tekton engine for pipeline by default, and has many moving parts, so is quite different from running a more classic like Jenkins master/agent setup in a Kubernetes cluster. </p>\\n Michael Neale <p>Recently, I tried to setup Jenkins X on a kubernetes cluster. However there exists some problem during installation. </p>\\n\\n<p>There are several options in <code>jx create cluster</code> such as aks(create with AKS), aws(create with AWS), minikube(create with Minikube) and etc.</p>\\n\\n<p>However there is no option which create a cluster with local kubernetes cluster. I want to setup Jenkins X with my own cluster. </p>\\n\\n<p>Can I get some advice?</p>\\n\\n<p>Thanks.</p>\\n jwl1993 <p>when you have your cluster setup such that you can run <code>kubectl</code> commands against it, you can run <code>jx boot</code> to setup your jx installation. You don\'t need to use <code>jx create cluster</code> as your cluster already exists. </p>\\n Michael Neale <p>I\'m creating a custom resource definition (CRD) with an associated controller using <a href=""https://github.com/kubernetes-sigs/kubebuilder"" rel=""nofollow noreferrer"">kubebuilder</a>. My controller reconcile loop creates a deployment sub-resource and parents it to the custom resource using <code> controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code>. I\'ve also configured my reconciler so ""own"" the sub-resource, as follows:</p>\\n<pre class=""lang-golang prettyprint-override""><code>// SetupWithManager sets up the controller with the Manager.\\nfunc (r *MyResourceReconciler) SetupWithManager(mgr ctrl.Manager) error {\\n return ctrl.NewControllerManagedBy(mgr).\\n For(&mygroupv1alpha1.MyResource{}).\\n Owns(&appsv1.Deployment{}).\\n Complete(r)\\n}\\n</code></pre>\\n<p>However, when I run my controller locally using <code>make run</code>, I noticed that deleting the my CR (the root object) doesn\'t cause the Deployment sub-resource to get garbage collected. I also noticed that deleting the Deployment sub-resource doesn\'t trigger my reconciler to run. Why is this? Is there something I\'m not doing or is this possibly a limitation of local development/testing?</p>\\n Chris Gillum <p>Using @coderanger\'s hint, I could see that the <code>metadata.ownerReferences</code> weren\'t being set correctly when running the following command:</p>\\n<pre class=""lang-sh prettyprint-override""><code>kubectl get deployments sample-deployment -o yaml\\n</code></pre>\\n<p>The problem was my controller\'s reconcile code. I was calling <code>controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code> only after I\'d already created and persisted the Deployment.</p>\\n<p><strong>Buggy code</strong></p>\\n<pre class=""lang-golang prettyprint-override""><code>log.Info(""Creating a deployment"")\\n\\ndeployment := &appsv1.Deployment{\\n ObjectMeta: metav1.ObjectMeta{\\n Name: deploymentName,\\n Namespace: myResource.Namespace,\\n },\\n Spec: deploymentSpec,\\n}\\n\\nif err = r.Create(ctx, deployment); err != nil {\\n log.Error(err, ""Failed to create deployment"")\\n if errors.IsInvalid(err) {\\n // Don\'t retry on validation errors\\n err = nil\\n }\\n return ctrl.Result{}, err\\n}\\n\\n// Establish the parent-child relationship between my resource and the deployment\\nlog.Info(""Making my resource a parent of the deployment"")\\nif err = controllerutil.SetControllerReference(&myResource, deployment, r.Scheme); err != nil {\\n log.Error(err, ""Failed to set deployment', '<2-hop>\n\nHow to resolve the error no module named pandas when one node (in Airflow\'s DAG) is successful in using it(pandas) and the other is not?</p>\\n\\n<p>I am unable to deduce as to why I am getting an error no module named pandas.</p>\\n\\n<p>I have checked via <code>pip3 freeze</code> and yes, the desired pandas version does show up.</p>\\n\\n<p>I have deployed this using docker on a kubernetes cluster.</p>\\n aviral sanjay <p><a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer"">Pandas is generally required</a>, and sometimes used in some hooks to return dataframes. Well, it\'s possible that Airflow was installed with <code>pip</code> and not <code>pip3</code> possibly being added as a Python 2 module and not a Python 3 module (though, using <code>pip</code> should have installed Pandas when one looks at the <a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer""><code>setup.py</code></a>).</p>\\n\\n<p>Which Operator in your DAG is giving this error?\\nDo you have any PythonVirtualEnvironmentOperators or BashOperators running <code>python</code> from the command line (and thus possibly not sharing the same environment that you\'re checking has <code>pandas</code>)?</p>\\n dlamblin <p>I tried to install ibm-eventstreams-dev v 0.1.2 into my Mac. </p>\\n\\n<p>After I installed eventstreams into my Mac, there\'s always several pods that can\'t run. It includes three kafka pods: es-ibm-es-kafka-sts-0/1/2, es-ibm-es-ui-deploy-69758d9dfd-kc2zx, es-ibm-es-ui-oauth2-client-reg-pgvq6 and there also have a failed job named es-ibm-es-ui-oauth2-client-reg. </p>\\n\\n<p>You can see the details in the follow images:\\n<a href=""https://i.stack.imgur.com/Qg3MB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qg3MB.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/n3YpQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n3YpQ.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/h4ZBu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/h4ZBu.png"" alt=""enter image description here""></a></p>\\n\\n<p>So I have two questions about the ibm-event-stream:</p>\\n\\n<ul>\\n<li><p>Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p></li>\\n<li><p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p></li>\\n<li><p>what\'s wrong with the kafka pods? what\'s the status message ""CrashLoopBackOff"" means?</p></li>\\n</ul>\\n\\n<p>My environment details:</p>\\n\\n<ul>\\n<li>kubernetes 1.11.1</li>\\n<li>helm : stable 2.10.0</li>\\n<li>a cluster have three nodes, each nodes is a virtual macine.</li>\\n</ul>\\n\\n<p>Please help me, Thanks a lot!</p>\\n DoubleQueens <blockquote>\\n <p>So I have two questions about the ibm-event-stream:<br>\\n Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p>\\n</blockquote>\\n\\n<p>Event Streams will only run on IBM Cloud Private (ICP). That\'s because ICP provides more than just a Kubernetes environment. For example, authentication and user management for Event Streams is provided by the ICP platform. </p>\\n\\n<p>That\'s what the es-ibm-es-ui-oauth2-client-reg job that is failing for you is trying to do - set up the OAuth integration with ICP. And that\'ll be why it failed for you in Kubernetes on your Mac - because some of the dependencies that Event Streams has will be missing. </p>\\n\\n<blockquote>\\n <p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p>\\n</blockquote>\\n\\n<p>I\'m afraid you won\'t be able to fix this in just K8S on your Mac - all of the problems that you describe are a result of bits of ICP that Event Streams depends on being missing.</p>\\n\\n<p>You can get a Community Edition of ICP (at no charge) from <a href=""https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295"" rel=""nofollow noreferrer"">https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295</a> - which would let you give it a try. </p>\\n dalelane <p>I hope it\'s ok to ask for your advice.</p>\\n<p>The problem in a nutshell: my pipeline cannot pull private images from GHCR.IO into Okteto Kubernetes, but public images from the same private repo work.</p>\\n<p>I\'m on Windows 10 and use WSL2-Ubuntu 20.04 LTS with kinD for development and tried minikube too.</p>\\n<p>I get an error in Okteto which says that the image pull is “unauthorized” -> “imagePullBackOff”.</p>\\n<p>Things I did:browsed Stack Overflow, RTFM, Okteto FAQ, download the Okteto kubeconfig, pulled my hair out and spent more hours than I would like to admit – still no success yet.</p>\\n<p>For whatever reason I cannot create a “kubectl secret” that works. When logged-in to ghcr.io via “docker login --username” I can pull private images locally.</p>\\n<p>No matter what I’ve tried I still get the error “unauthorized” when trying to pull a private image in Okteto.</p>\\n<p>My Setup with latest updates:</p>\\n<ul>\\n<li>Windows 10 Pro</li>\\n<li>JetBrains Rider IDE</li>\\n<li>WSL2-Ubuntu 20.04 LTS</li>\\n<li>ASP.NET Core MVC app</li>\\n<li>.NET 6 SDK</li>\\n<li>Docker</li>\\n<li>kinD</li>\\n<li>minikube</li>\\n<li>Chocolatey</li>\\n<li>Homebrew</li>\\n</ul>\\n<p>Setup kinD</p>\\n<pre><code>kind create cluster --name my-name\\n\\nkubectl create my-namespace\\n\\n// create a secret to pull images from ghcr.io \\nkubectl create secret docker-registry my-secret -n my-namespace --docker-username=""my-username"" --docker-password=""my-password"" --docker-email=""my-email"" --docker-server=""https://ghcr.io""\\n\\n// patch local service account\\nkubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""my-secret""}]}\'\\n</code></pre>\\n<p>kubernetes.yaml</p>\\n<pre><code>apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: okteto-repo\\n namespace: my-namespace\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: okteto-repo\\n template:\\n metadata:\\n labels:\\n app: okteto-repo\\n spec:\\n containers:\\n - name: okteto-repo\\n image: ghcr.io/user/okteto-repo:latest\\n ports:\\n - containerPort: 80\\n imagePullSecrets:\\n - name: my-secret\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: okteto-repo\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP\\n selector:\\n app: okteto-repo\\n ports:\\n - protocol: TCP\\n port: 8080\\n targetPort: 80\\n</code></pre>\\n<p>Do you have an idea why it doesn\'t work and what I could do?</p>\\n<p>Thanks a lot my dear friends, every input is highly appreciated!</p>\\n<p>Hope you guys have great holidays.</p>\\n<p>Cheers,\\nMichael</p>\\n Michael <p>I was able to pull a private image by doing the following:</p>\\n<ol>\\n<li>Create a personal token in GitHub with <code>repo</code> access.</li>\\n<li>Build and push the image to GitHub\'s Container registry (I used <code>okteto build -t ghcr.io/rberrelleza/go-getting-started:0.0.1</code>)</li>\\n<li>Download my <a href=""https://okteto.com/docs/reference/cli/#update-kubeconfig"" rel=""noreferrer"">kubeconfig credentials</a> from Okteto Cloud by running <code>okteto context update-kubeconfig</code>.</li>\\n<li>Create a secret with my credentials: <code>kubectl create secret docker-registry gh-regcred --docker-server=ghcr.io --docker-username=rberrelleza --docker-password=ghp_XXXXXX</code></li>\\n<li>Patched the default account to include the secret as an image pull secret: <code>kubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""gh-regcred""}]}\'</code></li>\\n<li>Updated the image name in the kubernetes manifest</li>\\n<li>Created the deployment (<code>kubectl apply -f k8s.yaml</code>)</li>\\n</ol>\\n<p>These is what my kubernetes resources looks like, in case it helps:</p>\\n<pre><code># k8s.yaml\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: hello-world\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: hello-world\\n template:\\n metadata:\\n labels:\\n app: hello-world\\n spec:\\n containers:\\n - image: ghcr.io/rberrelleza/go-getting-started:0.0.1\\n name: hello-world\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: hello-world\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP \\n ports:\\n - name: ""hello-world""\\n port: 8080\\n selector:\\n app: hello-world\\n</code></pre>\\n<pre><code># default SA\\napiVersion: v1\\nimagePullSecrets:\\n- name: gh-regcred\\n- name: okteto-regcred\\nkind: ServiceAccount\\nmetadata:\\n creationTimestamp: ""2021-05-21T22:26:38Z""\\n name: default\\n namespace: rberrelleza\\n resourceVersion: ""405042662""\\n uid: 2b6a6eef-2ce7-40d3-841a-c0a5497279f7\\nsecrets:\\n- name: default-token-7tm42\\n</code></pre>\\n Ramiro Berrelleza <p>I\'ve been using the kubectl to upload Airflow workflows to the kubernetes (/usr/local/airflow/dags) manually. It is possible to do this without using the kubectl? by using a python script? or something else? If it\'s possible would you be able to share your source? or your python script? Thanks, Appreciate</p>\\n Mihail <p>This totally depends on your setup. E.G. We use AWS and so we have the DAGs syncing from an S3 bucket path every 5 minutes. We just put dags into']","Deploying applications using Okteto in a Kubernetes environment can present several challenges, particularly when dealing with proxies and private image pulls. One challenge is that Okteto does not currently support using a proxy, which can lead to issues such as failing to download dependencies like syncthing when behind a corporate proxy. A workaround for this is to manually download the syncthing binary and save it locally. Another challenge is pulling private images from GitHub's Container Registry (GHCR.IO) into Okteto Kubernetes, which can result in an 'unauthorized' error or 'imagePullBackOff'. To resolve this, one can create a personal token in GitHub with 'repo' access, build and push the image to the registry, and then create a Kubernetes secret with the credentials. This secret should be patched to the default service account to allow image pulls. These solutions help in overcoming the limitations and ensuring successful deployment in Okteto.",multi_hop_specific_query_synthesizer
How can Okteto be used behind a proxy and what are the limitations of serving WebSockets on Okteto Cloud?,"['<1-hop>\n\nS3. I see that some Kubernetes setups use a kind of shared volume defined by a git repository, that might also work. Airflow itself (the webserver(s), worker(s), nor scheduler) does not offer any hook to upload into the DAG directory.</p>\\n dlamblin <p>I\'m trying to deploy okteto environment on Visual Studio Code to use Remote Development on Kubernetes.</p>\\n<p>Following the official steps (<a href=""https://okteto.com/blog/remote-kubernetes-development/"" rel=""nofollow noreferrer"">https://okteto.com/blog/remote-kubernetes-development/</a>), I executed ""Okteto: up"" and selected manifest(vscode-remote-go/okteto.yml), but got this error:</p>\\n<pre><code>Installing dependencies... \\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>By changing the log level, I also got these logs:</p>\\n<pre><code>C:\\Users\\user\\AppData\\Local\\Programs\\okteto.exe up -f \'c:\\Workspace\\...my_project...\\vscode-remote-go\\okteto.yml\' --remote \'22100\' --loglevel=debug\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""starting up command""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to get latest version from github: fail to get releases from github: Get \\""https://api.github.com/repos/okteto/okteto/releases?per_page=5\\"": dial tcp: lookup api.github.com: no such host""\\nInstalling dependencies...\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:32+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:33+09:00"" level=info msg=""failed to download syncthing, retrying: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""installing syncthing for windows/amd64""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""failed to upgrade syncthing: failed to download syncthing from https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip: Get \\""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip\\"": dial tcp: lookup github.com: no such host""\\ntime=""2021-09-13T14:09:34+09:00"" level=info msg=""couldn\'t download syncthing, please try again""\\n x couldn\'t download syncthing, please try again\\n</code></pre>\\n<p>This environment is behind my corporate proxy, and okteto.exe may not use Windows proxy setting. When I directly enter the URL (<a href=""https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip"" rel=""nofollow noreferrer"">https://github.com/syncthing/syncthing/releases/download/v1.10.0/syncthing-windows-amd64-v1.10.0.zip</a>) it can be downloaded using proxy.</p>\\n<p>Is it possible to use okteto behind proxy?</p>\\n Daigo <p>Using a proxy is not currently supported in the Okteto. We\'re looking into it though.</p>\\n<p>For now, a workaround is to manually download the syncthing binary and save it as<code>%HOME%\\.okteto\\syncthing.exe</code></p>\\n Ramiro Berrelleza <p>Is there currently a way to serve websockets from an application deployed on Okteto cloud given the okteto-specific limitations around <code>Ingress</code>es and <code>Service</code>s ?</p>\\n\\n<hr>\\n\\n<p>I\'ve read that this would only be possible using a <code>Service</code> or <code>Ingress</code> of type <code>LoadBalancer</code>, so that is what I\'ve tried.</p>\\n\\n<p>But, according to the <a href=""https://okteto.com/docs/cloud/build"" rel=""nofollow noreferrer"">Okteto docs</a>, <code>Service</code>s of type <code>LoadBalancer</code> (or <code>NodePort</code>) are managed. In practice they seem to get transformed automatically into a <code>ClusterIP Service</code>, + exposed to the internet on an automatic URL.</p>\\n\\n<p>Do these handle only <code>HTTP</code> requests ? Or is there a way to make them handle other kinds of connections based on TCP or UDP (like websockets) ?</p>\\n Nicolas Marshall <p>You don\'t need a LoadBalancer to use WebSockets, they can be served from an Ingress with a ClusterIP as well (this is what Okteto Cloud uses for our endpoints). This setup supports HTTPS, WebSockets and even GRPC-based endpoints.</p>\\n\\n<p><a href=""https://github.com/okteto/node-websocket"" rel=""nofollow noreferrer"">This sample</a> shows you how to use WebSockets on a Node app deployed in Okteto Cloud, hope it helps! (it uses okteto-generated Kubernetes manifests, but you can also bring your own).</p>\\n Ramiro Berrelleza <p>I was working on Jenkins for many days and deploy my services to Kubernetes.</p>\\n\\n<p>I recently came across Jenkins X, I also found a Helm chart for Jenkins through which I can host Jenkins in Kubernetes. Now I\'m confused if they both are same?</p>\\n RohithVallabhaneni <p>No they are different. I assume the helm chart you found installs and configure Jenkins on Kubernetes - perhaps configured with some agents to run builds. </p>\\n\\n<p>Jenkins X is a kubernetes native implementation of CI/CD, it uses some components of Jenkins, but has a lot more to it (for example, applications, environments, review apps, deployments and so on) for running apps ON kubernetes in a CI/CD fashion. The Jenkins helm chart likely sets up a single server. </p>\\n\\n<p>edit: in the time since, Jenkins X has evolved a lot. It is now build using he Tekton engine for pipeline by default, and has many moving parts, so is quite different from running a more classic like Jenkins master/agent setup in a Kubernetes cluster. </p>\\n Michael Neale <p>Recently, I tried to setup Jenkins X on a kubernetes cluster. However there exists some problem during installation. </p>\\n\\n<p>There are several options in <code>jx create cluster</code> such as aks(create with AKS), aws(create with AWS), minikube(create with Minikube) and etc.</p>\\n\\n<p>However there is no option which create a cluster with local kubernetes cluster. I want to setup Jenkins X with my own cluster. </p>\\n\\n<p>Can I get some advice?</p>\\n\\n<p>Thanks.</p>\\n jwl1993 <p>when you have your cluster setup such that you can run <code>kubectl</code> commands against it, you can run <code>jx boot</code> to setup your jx installation. You don\'t need to use <code>jx create cluster</code> as your cluster already exists. </p>\\n Michael Neale <p>I\'m creating a custom resource definition (CRD) with an associated controller using <a href=""https://github.com/kubernetes-sigs/kubebuilder"" rel=""nofollow noreferrer"">kubebuilder</a>. My controller reconcile loop creates a deployment sub-resource and parents it to the custom resource using <code> controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code>. I\'ve also configured my reconciler so ""own"" the sub-resource, as follows:</p>\\n<pre class=""lang-golang prettyprint-override""><code>// SetupWithManager sets up the controller with the Manager.\\nfunc (r *MyResourceReconciler) SetupWithManager(mgr ctrl.Manager) error {\\n return ctrl.NewControllerManagedBy(mgr).\\n For(&mygroupv1alpha1.MyResource{}).\\n Owns(&appsv1.Deployment{}).\\n Complete(r)\\n}\\n</code></pre>\\n<p>However, when I run my controller locally using <code>make run</code>, I noticed that deleting the my CR (the root object) doesn\'t cause the Deployment sub-resource to get garbage collected. I also noticed that deleting the Deployment sub-resource doesn\'t trigger my reconciler to run. Why is this? Is there something I\'m not doing or is this possibly a limitation of local development/testing?</p>\\n Chris Gillum <p>Using @coderanger\'s hint, I could see that the <code>metadata.ownerReferences</code> weren\'t being set correctly when running the following command:</p>\\n<pre class=""lang-sh prettyprint-override""><code>kubectl get deployments sample-deployment -o yaml\\n</code></pre>\\n<p>The problem was my controller\'s reconcile code. I was calling <code>controllerutil.SetControllerReference(&myResource, deployment, r.Scheme)</code> only after I\'d already created and persisted the Deployment.</p>\\n<p><strong>Buggy code</strong></p>\\n<pre class=""lang-golang prettyprint-override""><code>log.Info(""Creating a deployment"")\\n\\ndeployment := &appsv1.Deployment{\\n ObjectMeta: metav1.ObjectMeta{\\n Name: deploymentName,\\n Namespace: myResource.Namespace,\\n },\\n Spec: deploymentSpec,\\n}\\n\\nif err = r.Create(ctx, deployment); err != nil {\\n log.Error(err, ""Failed to create deployment"")\\n if errors.IsInvalid(err) {\\n // Don\'t retry on validation errors\\n err = nil\\n }\\n return ctrl.Result{}, err\\n}\\n\\n// Establish the parent-child relationship between my resource and the deployment\\nlog.Info(""Making my resource a parent of the deployment"")\\nif err = controllerutil.SetControllerReference(&myResource, deployment, r.Scheme); err != nil {\\n log.Error(err, ""Failed to set deployment', '<2-hop>\n\nHow to resolve the error no module named pandas when one node (in Airflow\'s DAG) is successful in using it(pandas) and the other is not?</p>\\n\\n<p>I am unable to deduce as to why I am getting an error no module named pandas.</p>\\n\\n<p>I have checked via <code>pip3 freeze</code> and yes, the desired pandas version does show up.</p>\\n\\n<p>I have deployed this using docker on a kubernetes cluster.</p>\\n aviral sanjay <p><a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer"">Pandas is generally required</a>, and sometimes used in some hooks to return dataframes. Well, it\'s possible that Airflow was installed with <code>pip</code> and not <code>pip3</code> possibly being added as a Python 2 module and not a Python 3 module (though, using <code>pip</code> should have installed Pandas when one looks at the <a href=""https://github.com/apache/incubator-airflow/blob/v1-10-stable/setup.py#L292"" rel=""nofollow noreferrer""><code>setup.py</code></a>).</p>\\n\\n<p>Which Operator in your DAG is giving this error?\\nDo you have any PythonVirtualEnvironmentOperators or BashOperators running <code>python</code> from the command line (and thus possibly not sharing the same environment that you\'re checking has <code>pandas</code>)?</p>\\n dlamblin <p>I tried to install ibm-eventstreams-dev v 0.1.2 into my Mac. </p>\\n\\n<p>After I installed eventstreams into my Mac, there\'s always several pods that can\'t run. It includes three kafka pods: es-ibm-es-kafka-sts-0/1/2, es-ibm-es-ui-deploy-69758d9dfd-kc2zx, es-ibm-es-ui-oauth2-client-reg-pgvq6 and there also have a failed job named es-ibm-es-ui-oauth2-client-reg. </p>\\n\\n<p>You can see the details in the follow images:\\n<a href=""https://i.stack.imgur.com/Qg3MB.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/Qg3MB.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/n3YpQ.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/n3YpQ.png"" alt=""enter image description here""></a></p>\\n\\n<p><a href=""https://i.stack.imgur.com/h4ZBu.png"" rel=""nofollow noreferrer""><img src=""https://i.stack.imgur.com/h4ZBu.png"" alt=""enter image description here""></a></p>\\n\\n<p>So I have two questions about the ibm-event-stream:</p>\\n\\n<ul>\\n<li><p>Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p></li>\\n<li><p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p></li>\\n<li><p>what\'s wrong with the kafka pods? what\'s the status message ""CrashLoopBackOff"" means?</p></li>\\n</ul>\\n\\n<p>My environment details:</p>\\n\\n<ul>\\n<li>kubernetes 1.11.1</li>\\n<li>helm : stable 2.10.0</li>\\n<li>a cluster have three nodes, each nodes is a virtual macine.</li>\\n</ul>\\n\\n<p>Please help me, Thanks a lot!</p>\\n DoubleQueens <blockquote>\\n <p>So I have two questions about the ibm-event-stream:<br>\\n Does ibm-eventstreams-dev only supported on ICP? Can I install it on my local environment without ICP environment?</p>\\n</blockquote>\\n\\n<p>Event Streams will only run on IBM Cloud Private (ICP). That\'s because ICP provides more than just a Kubernetes environment. For example, authentication and user management for Event Streams is provided by the ICP platform. </p>\\n\\n<p>That\'s what the es-ibm-es-ui-oauth2-client-reg job that is failing for you is trying to do - set up the OAuth integration with ICP. And that\'ll be why it failed for you in Kubernetes on your Mac - because some of the dependencies that Event Streams has will be missing. </p>\\n\\n<blockquote>\\n <p>How could I solve the ui pods problem in the ibm-eventstreams-dev? </p>\\n</blockquote>\\n\\n<p>I\'m afraid you won\'t be able to fix this in just K8S on your Mac - all of the problems that you describe are a result of bits of ICP that Event Streams depends on being missing.</p>\\n\\n<p>You can get a Community Edition of ICP (at no charge) from <a href=""https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295"" rel=""nofollow noreferrer"">https://www.ibm.com/account/reg/us-en/signup?formid=urx-20295</a> - which would let you give it a try. </p>\\n dalelane <p>I hope it\'s ok to ask for your advice.</p>\\n<p>The problem in a nutshell: my pipeline cannot pull private images from GHCR.IO into Okteto Kubernetes, but public images from the same private repo work.</p>\\n<p>I\'m on Windows 10 and use WSL2-Ubuntu 20.04 LTS with kinD for development and tried minikube too.</p>\\n<p>I get an error in Okteto which says that the image pull is “unauthorized” -> “imagePullBackOff”.</p>\\n<p>Things I did:browsed Stack Overflow, RTFM, Okteto FAQ, download the Okteto kubeconfig, pulled my hair out and spent more hours than I would like to admit – still no success yet.</p>\\n<p>For whatever reason I cannot create a “kubectl secret” that works. When logged-in to ghcr.io via “docker login --username” I can pull private images locally.</p>\\n<p>No matter what I’ve tried I still get the error “unauthorized” when trying to pull a private image in Okteto.</p>\\n<p>My Setup with latest updates:</p>\\n<ul>\\n<li>Windows 10 Pro</li>\\n<li>JetBrains Rider IDE</li>\\n<li>WSL2-Ubuntu 20.04 LTS</li>\\n<li>ASP.NET Core MVC app</li>\\n<li>.NET 6 SDK</li>\\n<li>Docker</li>\\n<li>kinD</li>\\n<li>minikube</li>\\n<li>Chocolatey</li>\\n<li>Homebrew</li>\\n</ul>\\n<p>Setup kinD</p>\\n<pre><code>kind create cluster --name my-name\\n\\nkubectl create my-namespace\\n\\n// create a secret to pull images from ghcr.io \\nkubectl create secret docker-registry my-secret -n my-namespace --docker-username=""my-username"" --docker-password=""my-password"" --docker-email=""my-email"" --docker-server=""https://ghcr.io""\\n\\n// patch local service account\\nkubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""my-secret""}]}\'\\n</code></pre>\\n<p>kubernetes.yaml</p>\\n<pre><code>apiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: okteto-repo\\n namespace: my-namespace\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: okteto-repo\\n template:\\n metadata:\\n labels:\\n app: okteto-repo\\n spec:\\n containers:\\n - name: okteto-repo\\n image: ghcr.io/user/okteto-repo:latest\\n ports:\\n - containerPort: 80\\n imagePullSecrets:\\n - name: my-secret\\n---\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: okteto-repo\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP\\n selector:\\n app: okteto-repo\\n ports:\\n - protocol: TCP\\n port: 8080\\n targetPort: 80\\n</code></pre>\\n<p>Do you have an idea why it doesn\'t work and what I could do?</p>\\n<p>Thanks a lot my dear friends, every input is highly appreciated!</p>\\n<p>Hope you guys have great holidays.</p>\\n<p>Cheers,\\nMichael</p>\\n Michael <p>I was able to pull a private image by doing the following:</p>\\n<ol>\\n<li>Create a personal token in GitHub with <code>repo</code> access.</li>\\n<li>Build and push the image to GitHub\'s Container registry (I used <code>okteto build -t ghcr.io/rberrelleza/go-getting-started:0.0.1</code>)</li>\\n<li>Download my <a href=""https://okteto.com/docs/reference/cli/#update-kubeconfig"" rel=""noreferrer"">kubeconfig credentials</a> from Okteto Cloud by running <code>okteto context update-kubeconfig</code>.</li>\\n<li>Create a secret with my credentials: <code>kubectl create secret docker-registry gh-regcred --docker-server=ghcr.io --docker-username=rberrelleza --docker-password=ghp_XXXXXX</code></li>\\n<li>Patched the default account to include the secret as an image pull secret: <code>kubectl patch serviceaccount default -p \'{""imagePullSecrets"": [{""name"": ""gh-regcred""}]}\'</code></li>\\n<li>Updated the image name in the kubernetes manifest</li>\\n<li>Created the deployment (<code>kubectl apply -f k8s.yaml</code>)</li>\\n</ol>\\n<p>These is what my kubernetes resources looks like, in case it helps:</p>\\n<pre><code># k8s.yaml\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n name: hello-world\\nspec:\\n replicas: 1\\n selector:\\n matchLabels:\\n app: hello-world\\n template:\\n metadata:\\n labels:\\n app: hello-world\\n spec:\\n containers:\\n - image: ghcr.io/rberrelleza/go-getting-started:0.0.1\\n name: hello-world\\n\\n---\\n\\napiVersion: v1\\nkind: Service\\nmetadata:\\n name: hello-world\\n annotations:\\n dev.okteto.com/auto-ingress: ""true""\\nspec:\\n type: ClusterIP \\n ports:\\n - name: ""hello-world""\\n port: 8080\\n selector:\\n app: hello-world\\n</code></pre>\\n<pre><code># default SA\\napiVersion: v1\\nimagePullSecrets:\\n- name: gh-regcred\\n- name: okteto-regcred\\nkind: ServiceAccount\\nmetadata:\\n creationTimestamp: ""2021-05-21T22:26:38Z""\\n name: default\\n namespace: rberrelleza\\n resourceVersion: ""405042662""\\n uid: 2b6a6eef-2ce7-40d3-841a-c0a5497279f7\\nsecrets:\\n- name: default-token-7tm42\\n</code></pre>\\n Ramiro Berrelleza <p>I\'ve been using the kubectl to upload Airflow workflows to the kubernetes (/usr/local/airflow/dags) manually. It is possible to do this without using the kubectl? by using a python script? or something else? If it\'s possible would you be able to share your source? or your python script? Thanks, Appreciate</p>\\n Mihail <p>This totally depends on your setup. E.G. We use AWS and so we have the DAGs syncing from an S3 bucket path every 5 minutes. We just put dags into']","Okteto currently does not support using a proxy, but a workaround is to manually download the syncthing binary and save it as %HOME%\.okteto\syncthing.exe. For serving WebSockets on Okteto Cloud, you don't need a LoadBalancer; they can be served from an Ingress with a ClusterIP, which supports HTTPS, WebSockets, and GRPC-based endpoints.",multi_hop_specific_query_synthesizer
